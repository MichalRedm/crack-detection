{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xea2AxvqAgQL"
      },
      "source": [
        "# DL CNN project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0itWhgqy3ySJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xci1LgFrYzPs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import copy\n",
        "import math\n",
        "import random as rand\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Lambda, BatchNormalization, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from google.colab import files\n",
        "import uuid\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BYQQ2ebp5ks"
      },
      "source": [
        "## Set up the Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "zE7veM56oOJo",
        "outputId": "d4d51db4-8afb-493e-c688-f081175d3959"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-552b713c-1ed2-4419-a97c-e1ba5ccf9811\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-552b713c-1ed2-4419-a97c-e1ba5ccf9811\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 68 bytes\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G-ZUSXWp97z"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ccBSoeimbnt",
        "outputId": "b3a22513-9b67-41df-e3ab-85a61b67c3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/lakshaymiddha/crack-segmentation-dataset\n",
            "License(s): unknown\n",
            "Downloading crack-segmentation-dataset.zip to /content\n",
            " 99% 1.96G/1.98G [00:10<00:00, 236MB/s]\n",
            "100% 1.98G/1.98G [00:10<00:00, 211MB/s]\n",
            "replace crack_segmentation_dataset/images/CFD_001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace crack_segmentation_dataset/images/CFD_002.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download \"lakshaymiddha/crack-segmentation-dataset\"\n",
        "!unzip -q crack-segmentation-dataset.zip\n",
        "!rm crack-segmentation-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr7N3l-_AM5Z"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VijajsizqNI2"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "TRAIN_IMG_DIR = 'crack_segmentation_dataset/train/images'\n",
        "TRAIN_MASK_DIR = 'crack_segmentation_dataset/train/masks'\n",
        "TEST_IMG_DIR = 'crack_segmentation_dataset/test/images'\n",
        "TEST_MASK_DIR = 'crack_segmentation_dataset/test/masks'\n",
        "\n",
        "# Dataset Instance\n",
        "class CrackSegmentationDatasetInstance:\n",
        "    def __init__(self, filename, test=False):\n",
        "        self.img_path = os.path.join(\n",
        "            TEST_IMG_DIR if test else TRAIN_IMG_DIR, filename\n",
        "        )\n",
        "        self.is_crack = not filename.startswith('noncrack')\n",
        "        self.mask_path = os.path.join(\n",
        "            TEST_MASK_DIR if test else TRAIN_MASK_DIR, filename\n",
        "        )\n",
        "\n",
        "    def get_img(self):\n",
        "        img = cv2.imread(self.img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return img / 255.0  # Normalize to [0, 1]\n",
        "    def set_img(self,img):\n",
        "        self.img = img\n",
        "\n",
        "    def get_label(self):\n",
        "        return int(self.is_crack)  # Binary label: 0 or 1\n",
        "\n",
        "    def get_mask(self):\n",
        "        mask = cv2.imread(self.mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask =  mask / 255.0  # Normalize mask to [0, 1]\n",
        "        return np.expand_dims(mask, axis=-1)\n",
        "\n",
        "# Main Dataset\n",
        "class CrackSegmentationDataset:\n",
        "    def __init__(self):\n",
        "        self.train_instances = [\n",
        "            CrackSegmentationDatasetInstance(filename)\n",
        "            for filename in os.listdir(TRAIN_IMG_DIR)\n",
        "        ]\n",
        "        self.test_instances = [\n",
        "            CrackSegmentationDatasetInstance(filename, test=True)\n",
        "            for filename in os.listdir(TEST_IMG_DIR)\n",
        "        ]\n",
        "\n",
        "    def _generator(self, instances, task='classification'):\n",
        "        for instance in instances:\n",
        "            img = instance.get_img()\n",
        "            if task == 'classification':\n",
        "                yield img, instance.get_label()\n",
        "            elif task == 'segmentation':\n",
        "                yield img, instance.get_mask()\n",
        "\n",
        "    def get_dataset(self, split='train', batch_size=32, task='classification', stratified=False):\n",
        "        # Select instances based on the split\n",
        "        instances = (\n",
        "            self.train_instances if split == 'train' else self.test_instances\n",
        "        )\n",
        "\n",
        "        output_types = (tf.float32, tf.int32 if task == 'classification' else tf.float32)\n",
        "        output_shapes = (\n",
        "            tf.TensorShape([448, 448, 3]),\n",
        "            tf.TensorShape([]) if task == 'classification' else tf.TensorShape([448, 448, 1]),\n",
        "        )\n",
        "\n",
        "        # If split is 'test', only return the test dataset\n",
        "        if split == 'test':\n",
        "            dataset = tf.data.Dataset.from_generator(\n",
        "                lambda: self._generator(instances, task),\n",
        "                output_types=output_types,\n",
        "                output_shapes=output_shapes\n",
        "            )\n",
        "            dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "            return dataset, None\n",
        "\n",
        "        # Handle stratified sampling if enabled\n",
        "        if stratified:\n",
        "            crack_instances = [instance for instance in instances if instance.get_label() == 1]\n",
        "            non_crack_instances = [instance for instance in instances if instance.get_label() == 0]\n",
        "\n",
        "            # Split crack and non-crack instances into train and validation sets\n",
        "            crack_train = crack_instances[:int(0.8 * len(crack_instances))]\n",
        "            crack_val = crack_instances[int(0.8 * len(crack_instances)):]\n",
        "            non_crack_train = non_crack_instances[:int(0.8 * len(non_crack_instances))]\n",
        "            non_crack_val = non_crack_instances[int(0.8 * len(non_crack_instances)):]\n",
        "\n",
        "            train_instances = crack_train + non_crack_train\n",
        "            val_instances = crack_val + non_crack_val\n",
        "\n",
        "            # Shuffle the instances for randomness\n",
        "            rand.shuffle(train_instances)\n",
        "            rand.shuffle(val_instances)\n",
        "        else:\n",
        "            # Random shuffle and split instances into train and validation sets\n",
        "            rand.shuffle(instances)\n",
        "            train_size = int(0.8 * len(instances))\n",
        "            train_instances = instances[:train_size]\n",
        "            val_instances = instances[train_size:]\n",
        "\n",
        "        # Create train and validation datasets\n",
        "        train_ds = tf.data.Dataset.from_generator(\n",
        "            lambda: self._generator(train_instances, task),\n",
        "            output_types=output_types,\n",
        "            output_shapes=output_shapes\n",
        "        ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        val_ds = tf.data.Dataset.from_generator(\n",
        "            lambda: self._generator(val_instances, task),\n",
        "            output_types=output_types,\n",
        "            output_shapes=output_shapes\n",
        "        ).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        return train_ds, val_ds\n",
        "\n",
        "    def augment(self, augmentation_dir='crack_segmentation_dataset/train/images'):\n",
        "        '''Augment the dataset by applying fixed-angle rotation, cropping a random square region,\n",
        "        and rescaling to the original dimensions.'''\n",
        "\n",
        "        instances_crack = [instance for instance in self.train_instances if instance.get_label() == 1]\n",
        "        instances_non_crack = [instance for instance in self.train_instances if instance.get_label() == 0]\n",
        "        diff_instances = len(instances_crack) - len(instances_non_crack)\n",
        "\n",
        "        for _ in range(diff_instances):\n",
        "            rand_instance = rand.choice(instances_non_crack)\n",
        "            new_img = rand_instance.get_img()\n",
        "\n",
        "            height, width = new_img.shape[:2]\n",
        "\n",
        "            # Random rotation\n",
        "            fixed_angles = [90, 180, 270, -90, -180, -270]\n",
        "            random_angle = rand.choice(fixed_angles)\n",
        "            center = (width / 2, height / 2)\n",
        "            rotation_matrix = cv2.getRotationMatrix2D(center, random_angle, scale=1.0)\n",
        "            rotated_img = cv2.warpAffine(new_img, rotation_matrix, (width, height))\n",
        "\n",
        "            # Random cropping\n",
        "            crop_width = int(width * rand.uniform(0.8, 1))\n",
        "            crop_height = crop_width\n",
        "            x_start = rand.randint(0, width - crop_width)\n",
        "            y_start = rand.randint(0, height - crop_height)\n",
        "            cropped_img = rotated_img[y_start:y_start + crop_height, x_start:x_start + crop_width]\n",
        "\n",
        "            # Resize back to original\n",
        "            resized_img = cv2.resize(cropped_img, (width, height), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            # Save augmented image\n",
        "            filename = os.path.join(augmentation_dir, f\"noncrack_{uuid.uuid4()}.jpg\")\n",
        "            cv2.imwrite(filename, (resized_img * 255).astype('uint8'))\n",
        "\n",
        "            # Add the new instance\n",
        "            new_instance = CrackSegmentationDatasetInstance(filename, test=False)\n",
        "            self.train_instances.append(new_instance)\n",
        "\n",
        "        rand.shuffle(self.train_instances)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset creation"
      ],
      "metadata": {
        "id": "NwYfjnnX2w7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NEOv6Oi_AO0-"
      },
      "outputs": [],
      "source": [
        "dataset = CrackSegmentationDataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxd5tz-sACOP"
      },
      "source": [
        "## Dataset analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFqyJOIBAEr7",
        "outputId": "845f2138-3d90-4be5-ab8f-331ab1c68adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of non-crack images: 1199\n",
            "Number of crack images: 8404\n"
          ]
        }
      ],
      "source": [
        "counter = Counter(instance.get_label() for instance in dataset.train_instances)\n",
        "\n",
        "print(f\"Number of non-crack images: {counter[0]}\")\n",
        "print(f\"Number of crack images: {counter[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4FyjVikqLJS"
      },
      "source": [
        "## Basic classification\n",
        "\n",
        "Here we created a very simple model, with convolution, pooling and dense layer with relu activation function, as we expected the basic task shall not be too sophisticated and such light network could deal with it.\n",
        "To trace the performance of our model while training, and to be able to use all kind of earlystopping, leave-plateau methods, we further splitted the test set into test set and validation set. in proportion 4/1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "5lktorLMZCt6",
        "outputId": "6acf44a1-1eac-4b9c-82b7-66e6f329305e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    204/Unknown \u001b[1m51s\u001b[0m 221ms/step - accuracy: 0.8590 - loss: 7.7557"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-be13dbed0634>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Train classification model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mclassification_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_early_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Binary classification dataset\n",
        "\n",
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "train_ds, val_ds = dataset.get_dataset(split='train', batch_size=32, task='classification')\n",
        "test_ds, _ = dataset.get_dataset(split='test', batch_size=32, task='classification')\n",
        "\n",
        "# Build simple binary classification model\n",
        "classification_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(shape=(448, 448, 3)),  # Define fixed input shape\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    # tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "classification_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train classification model\n",
        "classification_model.fit(train_ds, validation_data=val_ds,callbacks=[epoch_early_stopping], epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T9_A4u6FrEW"
      },
      "source": [
        "#### Evaluation on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbInIZuf_VBo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s2twNvwhLdN",
        "outputId": "e6314633-079d-4f87-92e3-aea67c46bc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 266ms/step - accuracy: 0.8910 - loss: 0.6267\n",
            "Test Loss: 0.6296\n",
            "Test Accuracy: 0.8749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Crack       0.00      0.00      0.00       212\n",
            "       Crack       0.87      1.00      0.93      1483\n",
            "\n",
            "    accuracy                           0.87      1695\n",
            "   macro avg       0.44      0.50      0.47      1695\n",
            "weighted avg       0.77      0.87      0.82      1695\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   0  212]\n",
            " [   0 1483]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "loss, accuracy = classification_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute additional metrics\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    predictions = classification_model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Non-Crack\", \"Crack\"]))\n",
        "\n",
        "# Generate confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEU9V913UKfl"
      },
      "source": [
        "### Imbalanced data\n",
        "As we have discovered earlier the data set is highly imbalanced with 8 times more crack images than non crack images in the training set. In the previous example we saw how it affected the model perfromance, it was  biased towards predicting crack and was basically as good as just saying crack without seeing the image. To address this issue, we devised several methods\n",
        "- first approach is to use a specifically tailored loss function for the imbalanced data. In this case we can explore a variation of the binary cross-entropy a binary focal crossentropy. this variation of crossentropy that accounts for 'difficulty' of examples . Since due to imbalance in training data, the non-crack examples are far more difficult to properly classify, this loss function is paying more attention to misclassified examples = non-crack examples, it is a boosting approach.\n",
        "- second  approach, we can augment the non-crack images eg artificialy create more of the examples of this class. to do so we can freely rotate them by some multiplicity of 90 degrees(to avoid having padding) and zoom, it shall produce completly valid non-crack images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3NnGkNYfW5z"
      },
      "source": [
        "### weighted cross-entropy\n",
        "\n",
        "As mentioned earlier: to leverage all of the data, but without the need of augmentation but still addressing the issue of the  data imbalance we can adjust our loss function to a tweaked version of binary cross entropy. This version will use  boosting on the non-crack  examples, as it accounts for the class imbalance in the training ( non crack being more difficult to classify trerefore mistkae on them is penalized more in this loss function)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zeict8uQf3De",
        "outputId": "15f02ca9-2759-46d5-9aad-e01bc3813454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    241/Unknown \u001b[1m56s\u001b[0m 216ms/step - accuracy: 0.7983 - loss: 4.9419"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 281ms/step - accuracy: 0.7985 - loss: 4.9266 - val_accuracy: 0.9183 - val_loss: 0.0701\n",
            "Epoch 2/10\n",
            "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 304ms/step - accuracy: 0.9370 - loss: 0.0542 - val_accuracy: 0.9328 - val_loss: 0.0548\n",
            "Epoch 3/10\n",
            "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 315ms/step - accuracy: 0.9427 - loss: 0.0446 - val_accuracy: 0.9131 - val_loss: 0.0845\n",
            "Epoch 4/10\n",
            "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 280ms/step - accuracy: 0.9553 - loss: 0.0337 - val_accuracy: 0.9521 - val_loss: 0.0559\n",
            "Epoch 5/10\n",
            "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 282ms/step - accuracy: 0.9619 - loss: 0.0333 - val_accuracy: 0.9500 - val_loss: 0.0609\n",
            "Epoch 6/10\n",
            "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 262ms/step - accuracy: 0.9703 - loss: 0.0266 - val_accuracy: 0.9167 - val_loss: 0.1120\n",
            "Epoch 7/10\n",
            "\u001b[1m241/241\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 267ms/step - accuracy: 0.9685 - loss: 0.0220 - val_accuracy: 0.9490 - val_loss: 0.0792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a5f258a24d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "train_ds,val_ds = dataset.get_dataset(split='train', batch_size=32, task='classification')\n",
        "\n",
        "# Build simple binary classification model\n",
        "classification_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(shape=(448, 448, 3)),  # Define fixed input shape\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "classification_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryFocalCrossentropy(\n",
        "    apply_class_balancing=False,\n",
        "    alpha=0.25,\n",
        "    gamma=2.0,\n",
        "    from_logits=False,\n",
        "    label_smoothing=0.0,\n",
        "    axis=-1,\n",
        "    reduction='sum_over_batch_size',\n",
        "    name='binary_focal_crossentropy'\n",
        "),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# as there is approximately 8 times less of the non-crack data\n",
        "\n",
        "# Train classification model\n",
        "classification_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,  # Pass validation data here\n",
        "    epochs=10,\n",
        "    callbacks=[epoch_early_stopping],  # Use epoch-wise early stopping\n",
        "     # Use batch-wise early stopping callback\n",
        "    verbose=1  # Print logs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LFymDo0gGyp",
        "outputId": "347b0d46-52ba-44ab-a02b-c25d3be38267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 255ms/step - accuracy: 0.9409 - loss: 0.0532\n",
            "Test Loss: 0.0503\n",
            "Test Accuracy: 0.9463\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Crack       0.80      0.75      0.78       212\n",
            "       Crack       0.97      0.97      0.97      1483\n",
            "\n",
            "    accuracy                           0.95      1695\n",
            "   macro avg       0.88      0.86      0.87      1695\n",
            "weighted avg       0.95      0.95      0.95      1695\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 160   52]\n",
            " [  39 1444]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_ds, _ = dataset.get_test_dataset(split='test', batch_size=32, task='classification')\n",
        "loss, accuracy = classification_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute additional metrics\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    predictions = classification_model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Non-Crack\", \"Crack\"]))\n",
        "\n",
        "# Generate confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5bIupEkIo9A"
      },
      "source": [
        "### Conclusions\n",
        "The overall precision is the best so far, but more importantly, this network improved the handling of non crack case, it improved  recall on these cases, so the network is less biased towards  just always predicting the crack on the image but mmaonaged to create more resonable model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data augmentation\n",
        "here we utilize the data augmentation techinque creating artificial non -crack examples to balance the test set. The creation of examples consists of picking on random, non-crack examples, rotating them -  by the multiplicity of 90 degrees, to prevent the issue of not fitting in the frame, and padding creation, and also later the images are arbitrarly zoomed to bring more variety to the dataset.\n"
      ],
      "metadata": {
        "id": "d6lvKno3kS90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "''' the augmentaing part '''\n",
        "dataset.augment()\n",
        "dataset = CrackSegmentationDataset()\n",
        "counter = Counter(instance.get_label() for instance in dataset.train_instances)\n",
        "# the augmentation of the data\n",
        "print(f\"Number of non-crack images: {counter[0]}\")\n",
        "print(f\"Number of crack images: {counter[1]}\")\n",
        "\n",
        "train_ds, val_ds = dataset.get_dataset(split='train', batch_size=32, task='classification')\n",
        "\n",
        "# Build simple binary classification model\n",
        "classification_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(shape=(448, 448, 3)),  # Define fixed input shape\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "classification_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryFocalCrossentropy(\n",
        "    apply_class_balancing=False,\n",
        "    alpha=0.25,\n",
        "    gamma=2.0,\n",
        "    from_logits=False,\n",
        "    label_smoothing=0.0,\n",
        "    axis=-1,\n",
        "    reduction='sum_over_batch_size',\n",
        "    name='binary_focal_crossentropy'\n",
        "),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train classification model\n",
        "classification_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,  # Pass validation data here\n",
        "    epochs=10,\n",
        "    callbacks=[epoch_early_stopping],  # Use epoch-wise early stopping\n",
        "     # Use batch-wise early stopping callback\n",
        "    verbose=1  # Print logs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H-nq0_KckcMI",
        "outputId": "51adf615-3d8c-4c87-abe5-f0728fd1cc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADoAAAGVCAYAAACvhuKnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABlVElEQVR4nO392a8lS5bmh/1s8mHvfYaIuPfmVBOr2VJTJKrVBAT9A6IE6N/kCwE+kYAAPgh6EvgkEtBjt1jd1azKrMw7RMQ5e3B3G/mwzHx7nEowd0A7KbBUO5G490acwc3NbA3f+ta3VCml8P8HH/3/6wf4X+rzTwv9x/b5p4X+Y/v800L/sX3+aaH/2D721i/8z/4v/1dUUfT9gO0sOWe8Dyze46yl6xwlZ1JKpBgZdzuMMZSSmaYJpTXH45kYIgoFWrPb7+j7Ducsu93A42GHUpALUCDlwvl8AaVwfcfpdMJoRWcs8+xR1qKV5r/8L/7z+y3UGENYApRCyRlKgVLY7XaEECi5oLXGGIPd7UgpMc8zWmtyLhirMNaitCb6gLGalCLQYaxBawUUUsqcLp5CYbpMpBAxxjBfZmKMJKU4Li9o27HbW7S57VDevNBlWTDaUijEGNFaY53srDXyoEoptNYUCjkXUGCsxmZDzoWu61jmGSgUCl3n5OtzIaVEPww42xHzK/OyoLVm2O/Y7/cczxeKUlhrsdYSc8YvnsvlfN+F7nd7rLU454gxopRiWRaUUuScyUWTSiHlhDEGrQ3WOXIKLMuM7UZC8ACyezmTYiRphzUw9iMAl8uEUYXOGIJWpBzwcYYccNYQYiQFz8PDA/O8QLnzjhpjGIZhXWSMkVIKIQSMMeSSKEDOhZwTzkGKCYXCuY6cM51zTDHSdfLf8ncOYw2zXxiCY5pmlAbvPTEmfAzEBEZDznL/S5FT1Q89eb4t+bp5oVprUkosy4JzDqUU1nUoY4khUEohl0KKEWsNRhsKcj9LgZKz7GQpskilSDmRcsRhKKUwnyd8CFhrUQqstRSl6foeUqKUyDD05FKIuZBCpO+H+y4057wamxgjOWdSzriuB6CUQilFLG2KWGPByA5773FOk3PGGIVSWl5clq9HrbYNax3L4nGdJVxmtHFopVFGFh5TAhQ5pXUDbtqoWxeqFITg0VpVS5qx1mK0hlJwzjIMPUYrlnkmxoD3nlIyzlmUKgxDR9/3dcfU6n7aDqMgpYVh5wg+4JwDClqLHViWhZwyGtYX5L2/6flv3lFrLSF4nOsoJTOOI8u8EJMnx0iikABKJsSI956u6zFGY50mRtDaAAqtFSkloveccgKl6TpHZxQPDzvmaaZQeDjseT0e8X5BAwpQKLxf6MYBVVR9GXdcaEpRdtBoUspyTLUc4xACrnP1CGa6zrIsnhQL4ziSUgYlR66UTEp53ZG+6+l3I85qovdMs2e3H1FKcTwdUVqLpfcB11n6vuMyiTGkICfhngu1xtB1HfO8rEZJdq1Da02MAescIUS0NvXrCtpoSpHjZyyklOtdNWit2e932HpEI7KokjPdMNLiks5aSkoorTBG46wiLWIfUoz3XWjOEsrlUnh9fSWEQM4RH2bGYc+8RPr6tTEmcimokpnnGeccOcufh2ahcwbkjllr8d4zjmO9y5ZpWQgh0rkO7xeMVvSdxVmNHgdyLigUu91434Uuy7KxvJoQJORTKEpJGGMppVS3YCT2pd6rani00eScsNbS970cPwoxhmrkFMZqgg/EmKCdBOfoncGaZvUD8zyzPzxQSrrvQrXW624c9jucNZzPZ1lgKsQsgUQpWQLvulAAbTTOGWKIDIPDuZ6u64hRjq+1BmMsSoM1ivHwRHo5sR86vPeEZSYHTQxyPY6nM103YLRG6Tvf0dfXVw6HwxrPGmM4PDxQlCIGMQxiYCRK0tZgjSVGcfLaKOZ5ph96KJoY4xp4xJhwrieGBYpCG8M8z1idOex3vLx6LucLXd/RdT3WLsQYWeYZ0922hJsXutvtAIjVdVij2e1GtLVoCvM003U9pca7u91OYuBkMUYcw9gPoBQ516inhpAhBGxn6Tr5WXIUFDkVzqczzjjso+VhP7LEjOs7YsgorUkx3/T8NwcMy7IA0A8ScpVSIGUG5yi50Pc9fd8xjgMPhwP73Y53z++wVgKJ3TDWuFbu5ziO7Ha7etwL8+QxxvD0/IBSinEc2I1D9bmRcRjorCXHVL9fnkNx56P7+HAgl8I49BK3KkgpoQqMu1ES6tWnKUmgU5JQMSW6oaPrOkJMKKVZFi/HzwcKCq1g6B1GqRoJJYwdWZaFvusZuo6YIikltO1QNuNDwChz0/PfvKPGaKAQgufx8ZGUCyFlfIxYY8g5cT6fKYUayMsRPhwOvHv3bhPmaUJIhCDx8m4ccdYSo+d8OnM5zzVBSFymiWEYGccO72emxZNRhBCJIa3Ixi2f2+/ofl9djNjS5jJA4tCu6wkhcjqfsNbhw4y1Gmc7vA/kFND1hSzLQt/35JQxuuCsYvaFT59O5KeC0prgI05ZvPI424sry0VeSk5MU6DvBxJ3TtOMtfTI3Xx5+UQpghCEMPP6+kpKks3EGNfd183N5IJWCqU158uExuKXBWc0wcD+4UBRhhQjs194fnpi8ZF+7NFGEws8HQ7k05n5dMHaTqItpbi1Fng7wjDuyCnx08efcM7hvUcpiXaUgkLGOoM2CoXEop3rxFQoxN/WYEIVXZNyZFeXgNEW02lyCdXwSSBhMCxL5HE30vcDl2lGW8P7d48M/Q4f7hwwkBLLNNFZx8vrK33XMU0LpcAwjHR9WQP8Un1qyhmKxLWFQggRUPgQUaqAshjToZVFK8lEliXhQ0BrzTQtgOKwH/j0+oKzYtB8isxzZJ484Ub38hXZi2BBqS7WGotzPYv3q4lX9X/G6GqBCyD/XhRYZ0kpUojiW1VGK4M1kHMkeAkPU07E6IkpE0NCI9kSTAAUVUixUIqvduKOCzVGE6Nk/r98/iXH45FcIKZEqQZhGAbBj2pSbq1mWZaa4jlyLoyjoHi5RMZxJNdFWaPpuw4fQj3SCa0MioQxgkg413G5XCT6ymIL7r7Q42VCK4W2rqZkhhBSTdFi3UWAzNA7MgJmOasx2jH0PTEXQpCTEYKmZLDaMHQWVSQoURVNiDExOIsdh+qzIzknco6AwXWuwi93PrqX83ndsZgTFKpb6QBWALpzHVopYgoCoRRdwewJlCUEcfpKKUKM5JQwjwcOuxFiJBex3lrVoKHTDGMPRbF4vwLiGU2IiVLuHBmxyeTPlzM5y70Zx5H9biClTEwRSka7jn2/Y1lm+r5fY9quH1h84HKZ5A4n2fVMJkRPShkfIssioJhzPTFFLhfPOHbEFBj6AXLhNMvXd/1t+ejNkVGqqIBRCtd1FOTeWmtwzqCAoesZhwFFoVQMNoRASgmrNCVFOmcwWqEo9M6xGwZSTJSSCSEyTzPjMKK1IanC4bAnl8J5WlDKkFNmGEcoGXJimS83Pf9X5KOCzDtryamFcwJULYvHWkfKCa0bjiPuwlpLyRlnDAVYVnQPOf4KUIlSw8au77HOYpwmpCw/swLmw37HPE8snz+Ro5yenO/sR40S7Od4PjMv8wpoBx9ASSTkai2md4IjaSMvxxhDcYbFJ5YQkLvssNoRkiTj3TCwxDPjMPCw3xNCYPaB5APOGbQqdFrR70d+/PhJ7q+ylHtnL5fLBeecZA9a17uXAEHiZVcNWims0wKHVvhlv9sx9h35dEYZwzxPDH1PyTDonnleuMyRGAIKg3dJLLpShJJRNUNJSYyV1g5je1K6bTe/aqGHhwPGGC7TmeSTgMchYjtHSpmd29F3vQDSJaGNwBx9N2Ccrb5W4tOHw56cE9M0k3LBWUNKgtqn5JmmC0obUEruZS68e34ip8jpPEvyXmFTd+/s5TJNHA47drsRZSzzPNF1PZfLGee6zQ6WutsSx/oceHwyBL9QSpYCrqJCoJaSA0Pf8TyOxBixzpFy4XiZK/hW6LuBeZ559/zMeVowJmOsJobMjVf09oUKvJnp+g7mwDQtzLMnZ0mkP378RE6FlCK73QDjiA+BlArH1xNaZSkjXmZSlEJLPziGoefx6YmnpwPLsvDx4wvGdXLcx5EUPc/PD/z6b39D/PiRlAsxJbRWDIO4tbsutOTC548vKA0hReZ5wVjH0HUojOCtnURJJWeMszhVKLPHWcMw7KoFhpQTnz+/kmKAojmdL4QkQYgPkV03oGvF21jDZfYsXqCcn//yV6QU8fPMy+sksOg9F2prfdRYw2W6EDNobdFaDE8pmVJqhFTDslY79UEM1W63q18n1e/OOcZhoADeS83GuIFpXihYrJNquPeex+dnjq9Hfve773nYHxj6AWMjKtwZqd/tRw77vWT/MRD8K8MgwYJfZsGIciEXsY5mmim5kFUhp8z5PKGUoHbnacIYizYGHwUrfv7wxHOnKVnx6fMraM08z3TOcZw8Tmuc6wkx8cOPP1UIVYC3uy70X/4n/7EgB0rhfeD1eAIUnZMirqIIHhQFEHNWyvsFKBUoG3qBW2KM5FLExSDlyG4QQHrxgc45UmWmUCCVQk4J5xwheJTS1WcXbqUb37zQP/+zPxV0oDrogmC8rlanr38mdZeS81rwnevxMlpJ6KiVVNQkjKLkzOI9S4hc5kXStFzYjQMpJXxITPNCzmkFw3JRK1HkrgtNKVWXIOFxQ+uVVrVoVDBG6pwhJpqJUIrqJzPOWlLOKARSWd+O1hLhKFVLHIlhcJW7AqhC5wwoqbqVXNaKwTbZuMtC24MI+qfJRRC5XM29UoqY5A0brQW4AikM5YJX8jWds2saNvsgcAuKjCImueNFaaghp5wATcgRpevXVqPnY4Vk7rlQpRSm7qLWGrcWeDLW1Ievu6u1PCTCsiEXOaYN4C65kLWiIHwGH6K8LOR3lFqSaLlnQX6GLgKXxpSJqaA1mHzvfBQqWWotjchD19JeSFmC7Fr7LLBWpEsGVFkX2nZDSFj1BYSayFu7FooVkIvGBy+If0yo+rJTlnuf722M5LkVnTVCs0lSK9VajnEuRR5eaZzRlJzleNeKWfvEWpLorFoZZspoUtJQv1bqrPLPzlqCsfS9fH1KBVNLjTEljL6zMVJaQK8Qry4l54yxhhISGtkR60x9CL2yR8SFRLlv1kIppFIoJQtGlGSnOm3W+yuGBrwP6PqilNIUlSlaSdpY/+yuCzWV6yf5ZIuA2luQmgpF4Eq5X/JXKWdyLoSYQCmsqXlsyqtFHmyPjpGUMtZqjBa6Xfv+mFKFRw2lFqFKLhituDEd/QqrW9+qqfe01WBClCNaAOfclZyh6pGuaIRAnGJVURqt5GUVkPtdd17Ko5LOpZSJUf7OV0aoUQprDMrI0Y435qRfZXUFEAMal6EuurNOXmxhjVRCZYCC7EqtW1wNUgW5S86gyspAobLPuup7837gMsuiSxbUb8mCKxij74/Ua6XJjcVVMq4+sNWC5xqtySVXd5CJKaOLWMUY8+p2VPWv1TMLv8FKcp19lhdQX6yzhqF3pCx57GX2KG0oWbAquSZ3vqNKsRqI3jiM1uLPckIVRQoRbRQhBnTFkGISnwcSOICkaF0n3x9iwmqNRl7eNVqSO51LIcRcgWq5Di0I0UO/Yst3XaiPwoR2xqyGSWsNJUu5IUphdvEepaklvVraq85fV+Qw1zjXVkZJbFdBye9pmDGo1eK2OyystQql3JiLftVCjTYSnlVGnnUWU1rxSdP3Xa2PUF8CdKulFhDNGCnmthi11W76zklomDImF4wSAnKMidl7liWQCihtUUVCyZRYs6S7LhQNptlyJVWzZua1UqgNM9toA1pciTWWcZTdTTHhK4oIkFJY3VGuhqpzcidzI6d4iaJa+Km0II1zLKAtzt2ZfmO1qXFrxfOK8OWdVpJwUlDW1WDftPchRqVWvYNSJJoFlwhHLDI1p60paHUbufJ597udvMxlqfExZAox6rWSd7eF5lwqkbjuRimoVN2NkvvUd25Nm2R3a4iYxL2kannlZ0kSkDLCaHFmtciN5OxDqiGj8CWsMYSUSKm6l5rX3nWhsfnQJA+otGYJsZKjDH1nVu5f66CgPnB7eEm0a+i3pn3CIwS+sKLWamKSuxgqjx7kZ+ScpBjlA8O9cV0FNf+r1pa4Zh7WqDUo0NXSaqXI9RtLbdaxRqEyWGdqW0laW0mEnrOut/5cA13B1OCBolC5EClC+bFSzLrrQgX0yms0pJS4A6UaulCRBqmlQZFEPMRU8SNNyqwuRStFLhKvtmyl2bqc5f9aaywWYwqByBLlNWglXRNKS1R214UCdM4KicmJ5RMzn8ikiqpTIydWVJACIWSck0jHKEUhSyrXWVJMpAaV1jwhl7zivMZoVD0luV4F5ywpF/qs1+ThbgtdfGAc+mpACsoKEpBRVKxPLGtOYrRqR5NwdHMNE2XXSixXBE+1a5FW7CnGTEgRow1aSyKgtGYcB+Z5YVo8IUSsVvePdaUUn4hK0Tl59c4aTJFMBNpulNVwtBi2vXbBlnSlwGVyPdrzIjSegiD1CtAVb4w1zeudQWcFXSd3PhVCCtyap9280CuOWn2oaemaJN+60uU0hUReS3pKtaaeQkwZpSRNSVlQipQSIUo/TIqZUl2RNg1fkt8vxOhIqpGVtJhcs6W7LdQaQ1YZpY10SuSCUu3hNZ1RKwYk+Zh8Xa4X1lpDjHm1wqjaxAfsd7q6ECgpCSSqxMXoauzmxXOeloo+qBo2OnwFAu620JzL2phjjV59pDVaeO9aCcabS4U8ax+oKmjke7RSLCEK9lPZnqYe677rUASx0k4LMI7E0rlkwYytFYRDmZpQlPvzjBp0oqq11fUhrZVjpGs4l5vlpN1VwYFjkoc1FUyzRo6cVoYSxOpaoxn6bk3Oc0oV3zZi6FokRqlVuXz/NE2vi1P1SGls7ZhQVGJTReFbuAjScWi0WwmSubZorSlbzmtk1JhgSil8CJSiST7WuwjO6lpMDtjKL7x7g49Am3I8tVI1AC81IhIbKTi6fJZlQaEqt092Nlegy1YaXTu6LQvKpTba5lxDPbkaIUrhVyt5EcZkAbSVvv9CndWkVGrTnKJ3QoMLm86kUnco5+ubjqmmXLaswbn8X69+UymN0tKS2Rp3BHbJlPYCW/RUysrRXTuP77nQFtNe0yJVg3P5d/GXYmGVVgxdt0KW1pqakbAC0w1FaClZKQofPEaLIWqNRF39baVkCSpQa6Kgy61J2lcstKvlwVYCCNVQWHMtBjVQSyIeJR2C6or/NgtbSmuUFV8qR7lU1L0IR7CUmuG0zE8sd67pXYiJWGPsuy608YkkE7m2buUkoJbW8kQh5jWQKNU6NnRgXWDl/LWCVaoPrKL45RYEKCUM0JaUqyK9bN4LlzcVGPRtQf3NXMCWal1mX5kh8rC+3atqlYXCsFZHAelMarvufai7JUF8syW6gtzC1c0sixcLXcoaK5eSK3Ys1pw/BmZUKgQpwHUzNAlr7AqFlpwxSpGVlu6FCqu4mnCHms+2UqAP8XpnU8tO5Pf1fSewqQGFFICttbW909W6jK+NfHdcaKrIgqsOX/ZK1TsKwYd6FVXtlpDCUdGFJQSUkhMhCL754hq00mOpzl/8ae0BLqCrLEGhYJ1U82ISmPVWmtxXJN5FoKGK2caUmX2o/lVcTKkiE9poKSYVqaLFnBn7DqPBwxfWlhUSq+e4Qi6mFpMzMM3zatT6zpFiBc6sZbw3lHI6n4WRmavoQ72nn/2CNZacE60XxlnZjYJi8VWcYl5qGf6a04XUyv2GnGSLWzIfY8EoLRFSVQhIKa/ljBC8FKvunb2EbFmmREyiY5JilIdIkeAXPr28QMn8i3/+l3zzq59zmhYu54mfPh8JKUtHYQ3vUmWTFAWd6yq1RvQcVE3Bhq7nsHc87XfYCt/EDWb1y58XzpNfc+G7LfT56cBlmkEZIVTFKPiQMWIkXIdWhVjgh4+vvHt+5nS6YK1D6cK426FQHI/HmnxL00+IiXEcUCgG11VNFsPjw4G+s2IXrCOmiAEapdU6zc8OD/jlNnmCm93L0Dm0KhiV5SjFVOswWu7K0HM4HEgxcjoJ5x7Tga6IX4g10c411EtiSApIhiM/S37OnqfHA1qpqttgpCyRyia1K9KZeO+K99/+3a95eHyojQBxtXau68gxSq7pI++fDxQUH19eWUKiZKmTGuuqpbQs04WUNMYWXNeRasnBdo6x77FaC1itFLYGFBIxZUKQqniMgcf97maZn5t39P37Z94/PZJzqYTihKagKYRUeNjvedz3nC9nfvej0E1LkVxSKenPXpZZGvOGAeukYdb7wOeXV0IMOGNwRvH8+IDWRkRfqsvRStfsReEXz353AKVY/J0Rhm8+vJdu+gzaGHqnOex3xJTpnaU38Po6c77MFC2wJtbgvZcib85Yrfn06TOKwm43Crd3kI5CDVAyyxLov3HklKQ1rDYl5JxZfBRDZu0aThp75yJTzhlfYY1hcAzOMs3SGNA7w/7xkW73wMvrC99//wNdZ6tkgfjNxXtCjIzjwDAMws+PAWuE6PGwH5mmmXHoia09JMaKJcmudp0jxSgF6AI/fL4wXe7cDvLyeuLlPKOVYuwsWhtyyOhS+Nm3H5hmLzzbIju+zIHn5x2PB0NM0jX8ej6TS2YJQcJHa6TIlAKn04UP758xWuG95/V0WiMmqw273SjJuJKMJyNoQ0sU77bQxgNMKaGNIRV43PU4J/EnpTBNF06no5QKq8rNNC8cTydiSkyXS+3h1lW2YBBIRWf2hz0KJfc/xbUF0zrLsOvx3ks/eMmAxkdAaXK8s/rNZV54PR7prCPZRIoJux85n890zvB6PGOM5rvvvuPHj59QJdfWyEjMhfNlll4V09I7Ab9M13EYB2Iu/PTpMz4INf2wPwDSfypl/FxVOTq0VsScmZZAuDunvhRRvzC61j0lQLcVyB7HgY+fPq+NckYrUgycTycKIh8ynxZyKRwOAlV6L5plyVpB9ZGMhsp+eT1e6LsOlOYyTThjGEdDioVlCShUFWv7w5+b3cthHHBG/NfpdJb0aGP1vv/hx9o4kFjqcc0poYylAPPia1leYoR+GMgpkarkQGvN9MHTVWa20cL8PJ4nfBWY8F7Ud3IKkBPmxmrazQv1Iax4zX4UHvv5MlFyYZpntDYczxN/83e/4+VV7mmuwNayzCzTREmpIu2iMEcNDIZeKOR9J80EMUR8iMK5DwEfIrm0UqLAK851oNX9OQwZxTj0GF+xWH2FPENIPD4e+O33P2Ks47J4Pr0cUcailOZ8PletlT2XaQEtDQe7/Z6+73HWUPqeyzRXUjPS/pEL1jlB40uuyXpCq0Qu0rHv/W356M07ao2SMkMS/ntOiRAj8xJ4enwUvrtz9IMcuyVEES0spQpDdDwcDvR9J63MxjJdJn748Uc+fvos/Hyj10BgmapQYlGiUodi9qnqEiZ8LJwuC/O9g3prJdNYgl8LvikmFh/4+9/9wOtpph9HKKIVJp3CtSIG7HdVDmQYxD2lGtRzZXanXHh+fMSHyKdPHwkhSm6rNIuPnM4XXk8XqKGgGLQ7uxey5KApJYahF6W4lHEUrHVo6wTMvlx4enrgcrkwDh0lR/70F9+hlOI0eWa/yN0u0gQv5ZlKb9UQY2DoLH/+p38id7MSnENtJ0EZhnEkJuj7Qla3LeGrjFFIwse1WlX9zIT3gR9+/Cjam33HN99+g9KG3ThgreFh7Hk4HHh8eBQ9oor0qVrG6LqOZfFCUzWWyxJAG/q+5+HhIJBL8ML2jIGht0wXSQ6c63D3zl4+v7zwsB9XKtw0X+idQSnohoFU8VuF5K4oxfF0kTSs3mcFHE8nKRlWCk/OCW2slO+NwXUdwQemeRafrGA39qQQpHs/Js7TxOl84TzN1e/+4c/tSH3XEWLkcj5L/SNJzOr6AZThcrmgjaodwa7iP9KZ9O033/Kb337Px0+fVjqrMUb6YFIGLR35MQa6YaCzhuPrq9DncgFj2e93wtsPIqyIsmLVb+TUf8XRjZUNrclFKKbv371j6DucUcQkylVCQY3Sg3Y68etf/z3TNHO5nFddTms0XddhjOgMlqr3OY5jbTaAX/zsO0nHgKHv1t7UUo1X5ww5Bl5fPt30/F/RKCuNqz4EgSJVbbBBifyrtnSdIaYsWmDWMowjIQZ+87vveX565Hi+MM8LIUZ2uWDqzoeYBBxXCp0CuhRm75l8FPhkmfHec+iHqtqhicHTO80vvnm870IVRfQTKi/BGIePlQtkLa7vpS3LidEQJYxM3zn+9u9+zenpEZAAIEahuKkkxA1bS4mn84X9OKCsxYdI3zkul4nLxTMMordgjUaZrlJzVM1y/vDn5qN7PF+Y5qkSjiVjyClxmWYus6g+9rUsbzcc+2URjezj6STyWxW1N7Vb4qePHxl2o/AUrOU8XQgpkmNA5UROoscrjQmm7n6upKvMfG+Zn1IKfdfjrGWapRfUDT0H54ghooHz6bj6xbnmjjEEkbjrBnKKYmlTJqqEKoXnpyd8dS8lJ3bjIFgxME8LLy+feXx8EgxqmsSthUgpHbXmdNPn5h19enzAWMPpcsGHWHu+5Qj344jru1UKKIZQ804rsAgKlNRYXl9fsJUjZDtXATJf4ZZA5yzWGoL3/PrXv+bD+/c11i3sdyO7oUOXxNA5Hh8PDMOdhYRLUWv7hlaCEOSUmCrxYplnQgz4xeM60TuapnnFZrUukKHvRT8hr4wSSb2c62qLJvTOcSlnHh8PzIsIoV5l4Uf6oV9R+3zvHu9SubKl1OLOKNKwMUZCFj0E4ehKkfh4OkuJ77AnLPOqNqeQl2WN5Xw5C0u0VtOdtQx9R/CekgsPhwM/ffrM+/cfpLYDTNVqOys8CHVvAURrpXFVoQjeE6Mkwq1X1GjxjaJw47FK2F3jbscw9MQg6snTPAkTbJ6rs5dd0ZVddp5m4T5UBsp3336H0obn53d0riMVKt2uEHysnPwbnv/WhUqrkcI6hy6FJXhSTlhb+bu185B6VJMxmGp9p2ni+d17Pn78KLBpkDu52x0wRlcZeCr3SDPNC9p1GFVYvCThs3PYWptNRXE8X+id0OTuutB5WVYE0C9L7T0RFvXQd1deQyt3olbVDWPFKPV9j0KQROtkasAwjGuVWyvF548fRUvb9aANIVYVdSQ6mxeBWgyC0s83Jt5fKa6mV368s7ayvKR3tLeWHDw+RtwwrjpDMUm46P2FzjoRhBl3KK25nM/iZ43Bdg7jHLvDAU2pvaHSTlJSYp4mtJHM54cffuThcCDGRLzRv3xVxTtXtwJCYTNZYt+hUtyUNfRdhwZ5QKAoYVD3rhOsp+uZp4kP33ygq70yr69HxvEdp9dXbNfRWSn9T8tCUWoNFYXPlNjvdnz8/ILth/tHRlAF9yvPx1pT+1pYra1CCBvTNJGVRjtXU61Ksy6FvnPrke9rxJNS5HQ6QYp0RkvXVG7i4NTyolTUFi+R1Z/84mfSeHBjyHB79uI9qi6wyUALm6SwLB5jLD54fBWPqY2gqPrv1oq/LIjM5b//H/+Wl9dXpnlhvz8IULbbU5RmqcFICp5csyJpVqgy753I5hlVeP+0v+n5b+97qWrlci/lKGutcV1ddEULQoigDTkEKKKKPI47pvOJeV54eT0xzxPH44lf/eLnKGM5LwvLsqD7AaUlsmoSeSjRC9RGk1MiVg2zXd/RdZZx3N30/DfvqDbi2H1DAEPgdD5JwOCvcj8+BJGSrezoru85n468HC90vWhfW+v4D//ZP5MWkyjjT0yVOMjRo9VVkqBUUlUTaWuVdqHKmfv70d5JxNJUVbu+ZxgHOteBK2tIl1PieDxKF2E/rD2kh8MeoxUvn4XU0VVZr2ma2e13pJjpRil5+BCFF+x6yHI/fZRa6jh0lBRRVsqPd29mf/f+mVit7m4nsj5Gm9pumXHO4ZxlWfa1l1v4CrkUDrsduh75h/2OrusoKKZ55vn5UdC90mRsI/v9HquBIvf5eL6szG+UYpom+kG4DUL1ueNC3z8/sSzCKXp8OFQ9BqTjoWpUlwKzX0gI6Jxi5LDfQ0UmVAXPjFaUynloje2uCk2cp0nyVQVj1zP7pdJie6G7Pj6Qc+b1dIKcGMc7GyN5QJENSSEQK/0757RCjqKx6/DzwufPn7Fa87Nv3pORdpLWKhlqJ4TWWvrXUCu5MaYkkGjtLHRVg8zHiLFm7VxUlS/8+nK870IvsWCNJRTwlS4XQxQZy76nxIjShouPnOZAtgPneeJ4nsTnVkizSYFQW7BUazqoylVj39E5SyyKl+OJsRd3cjpfSIuAb7FSZ0vi/hrY/+avf03noMTIt9+8493zEz/++JHx8MBpivhlwllHVobFe16PE99//xFnLLtBun77viNkOF5mHvYjpSSs68RVoZgWzzJPkoQnSDHz2/nCYT8wXWaWeUIrGMdRFloxqbsu9M9/8cyPP/5Ev+vY95bRGX7+7TsuS6TrDKMbeTw8iAhwGnl+2PH544887Eeenh5IJeFjoivwztl1Gk8qheN5YuidNPfpEa01u1x4fT0y+wsLgRQCg5O5bVoriioiP3LvWBcFjw87OmuqjIAEDFYXeqNw3SiNc0az63qKgl/+/APDYElJmtFjSNL7beXeaWMoSWLXXDKZQkhALlzOFz799AmnFcY6shIsN2VpGOg7GQ738vnzfRe6HwcGZxj6vrZNana9gZxZ/ELMguLlXGqbhq44kyUV6VbU1lXNsZnGzE4ozj6Tw8LQWS6zx2phZz88P5H8Qt9bDv0jKWXmeUEr2O8fsM6uM6HuttBSRNRba8XoOnLtWphj4sefPtN3jmH/gDWGS0jMIfNymhnGQQjKpZAmj/cLwyARUioCqdiQKdUndkZYnCEmumHg5XzGlIBxQ2VyZqZZajJ+Wdae8z/0uTkE7DrHbhwY+h5tTe1nkZLhL3/xM95/+EAIgSV4UBBi4McfP0tp33tiKkx+IUs3AIos8gVaM3ZC4bHGCN2md3XUiqPvemK0vH5+rWXGwtB3+GUhBM/59fWm57+9wUcrVIG5dveVAkUp5sXzsB8JKfH4ILqBSmk0C36eKTEy9AMyq2m3Fp9Ska6H5AVBcKqnqEKmdinGhFaZ0RkShd3zE64z9F3P6XRC5cg37765v9LjbtwRkkCM58skiqpFAoHZB1zXCcFRQwgJ2/WMT++FRudEvKXBpf3QicOvjv/aIw5DJxW2bBRDZxisqFKN4yCc+qGyY8LCh+dHbqQZ3b7QKYhSlDbSWumjJMZj5+g6x1KDB1UMl8tMRtFrUbMJ3gMKnTSHwwENEmhARe4TMamK7DcNQbnX+8MTn19PfHw50feWcah6Drbj48uZy408o69o2dIoDSolOqtrt31F7iqdVZeEQrMfHZdp4TDaqgUo7iCmyOV8kqNcOyByiVBUFeeQ/haR8FJ0nRCt9mOHJTMtnsO4AzSXy4VpOt/MwP4qwYlOScdvP4wVPY+kKjqhtBb4seuYpolpmoVLH0UdQ2g0gvxdqsZu14+Sk2YZq9Dmv1ijq5CEDLPyIQqHYehJBWYfWGIU7c7xztnLvCzQufWelUVgk5gis08oCs9PD8zec5kDPiMl+5wZeksMvnYQutoTA/FywtpunUzZ2p+11nS9Y7pMvLy8iCxCHaHy6eNPsuMl15kTd2Z3mtoz6qq+SeeMNJRT+PxyYug7hiosYfZSnidlPjzssF3HZZpWXYVu7IHCTy9HdjtpHzFGM44957PwExSKZbowdNLb0vc9PkbG3mG0YZq9TM+7d4OPlOWlhKBME5yQbqYP7x5pM9VQmnmZuMyBz68XOmcpF0/wC0Zlhn4QbClnfvw88b4YDqMVeFRrtDE41xGywvR7LjHS2x1LCkyzlwEbSSYAzVUl8q4LPU1emlZ7GVmbd8M6WMZaS+ccuWR++8NHPr2cmaLi3/673/IwWHZjR+/EB469UFZVzowm8XTo2e1kbksuhYf9jsOeNT+9nDOX04mHneNhP0i5Umt2uz3TNN+fgX0YeymrQyUaqpXaSsn8/W9/x2438v75gWEY+HyauXzzwF/8yXcyhSdLvNsk71JJ/Nmf/kKmSK+NP2U1WDEElmniF988MgwiHl4QoqVfBLuyRvP+/bv7LrQB1/MiTOhxTDjr6JQE2j/89JFv1TccJ09ImeNpgRy4TBPGWpZlYa4yJMY6muhwyhM5JZaYmOeFw25P13cS3p1OLLNhfzhwuUxrC0quzbXn8xHuPTTjcpmER6BkLOe8BJZFynbny4Vh3IuQoTVoQBvFOLgavBd6KzOXYswoK5NBUpKeGL8E5suCcYp5mdC6kjKU5vUkxClbZx/6KNIjfdfx+eWEuhGpv11Zwxp6Z+tA1FFgk3lBa8XQ93R7GWQjZCmLdjM/XE4oo6XVyhoGJazOEKX9Cm25TBMlCZL//v2z+F/v6fZ7DvtROEY+YLRiGDri61EsuhK+/ePjnek3u3FgHHo6Z+VBnMG6nYxJcFYkClSlw1S9BMF0S+36lb7vVKUHTEX7o1EMvSUlodblXPh8PFPOE0+PO0Ax//RZALKQqv6Y5vj6yjjuWKbpvgu99nAnihaNk5hEhHs0Ui85TgsPhz1Ky4vZ7fdyR40hLB5nQLv+qvhYQFsZv9CNvVTAm1avjiw+4pxlf9hVScuMrljR/nCoU2vvHBmFEKV5QEkv8FT1FULMLDlQslS55pDwS+Tjy4Xf/fjCr372npQLp/OFh8MIfmEJmRQDfS/Dq7xW9BiMk+YdW6WtdZUEMpUTkapieooBU5Vvxr77g8/+VQtdfABVhw8XVeW1pMlVKUvOPTStBGVIRUJFH2XY8TCOEg93HdYVYhb2V2NnG62lvqNUtQUdr6cjznb0g+P58YFlFjbnTIIkc9f6e+vUex/Y78daZCqUoce4jlz7xnyUrl1VMiFHQvB1SsGCc1IdR0tjkMAxvfR6K1hiYQ6RPC/4ZcFaw7R4rBGJTG1F+abvXJXTlDbNoe/WmVB3W6h1wthy1lK0uAtKIpEoKVIqs6SlbykESInRGXaH3aobJoIvkVgirtOoouiMJmGYk3RDtA7C6TLVkUdCtKJIgq4RSZHzWeh0d11oCJH9bqx3VEhUxmh0FpRg8tIW2Q8DJiZ2w4A/H3l+OAhyyLVaLrxescYFUDlhFQxdx+UyYxXYriMGv6IYAo/KPCgqN+n4erx/PoqWsUAFZFCNUoRcoGjmEFBauoKV1mA1wzBQdIdPmZ4q+6MUqSiWZHBGYw2rWHjJCVPFobQqUiLsraARtXleG9nVrh+YykQMnv3hcN+FfnwVJC8ri9Wap10GY5jnSIiiuPjxNGOUJmT4/sfP/Nt/+zc8Pww8HQYeHx9IBT6dPT98WvjF+x37XhbbtO6dNYyd4XhZ8Iun64S2M4x7Xo4nlnliHHuW01mms/eDyHvdc6H/4s8+iPqNEumBzspOTLoQgsg7+1DqABvL+6cdf/kXf8Zf/W//Yq2anS8XxvGRn70XdL8NfCxKpGaVNhz2OzAOq+T8aFXISfLQp8e9+E6l6N2e3dCxG+48xzvngOvHquGZ0LpDFxicwRk4TTLDcL/biWSPKXzz7iD9MRUmnRdPwfPyeubd00GmuiuRDtJG6qQZ6J2Qn8MyYV3HEiQmTkn8cYxRZjGVzDjeeaGliHZnSBlVCsaI0GjfO85TqjpEBq00w9CjSsFbTUiF8zwxL4GmMNc5K2zOqr7cGvTCMkuIrjWny8TD0LPEKJ3AScDr3nW1HcTw+I3Q1++60N0gNRejinAPZs+0BPaDyBY4a9bqNaWISHdYUJUV6mphylrL2HciDVRpPE3ma/JLFTeVoOHlfJEJtFry1V9890GKVSnRpUDK6Tps7l4LLShyEZmQlDNj3/P59USJgd3QVY6uTP/QWuF9YvGC7o19x9jLxGdjLaGKxgQvs791bZ/0PuCM4hLKauH7vsNZyXg+v56YLxecLjLub5p5fHq66flvrr1I/tj4RD0omX82jD2uc9IpXBRFGUq1vKfZU5DBNhmF0oYlBBlUswTmeRHurnOcpwXbD/gsIjDSvaR52A04a3jYDZAjg9Ps+o4S48o1uuVzO64bM/3QM/Sd6BYZQ0GUGHd9h4+Zac6M2rIfOwIGXmaBWoxirp3CfdfhCuyGDqUfRV6rSMo2BY9BoUoWfKlWAWLKeL9gKj09VmZM3/cig3DPhVpr+cu/+Av+w3/+l4TKx5PhM9KH3cQObTVIIQa0NtIbWuC/+b//P/j80yf+9Fff8u7pCRAwzNRmn4fdzzB1gEZJBeMs8+LZjyM//vgTjz9/z1/+8/8NtTCwzhS+THeupv3Vf/IvOM8LfdfR126jEBOhZJL3DDU0U+o6aEoMRdWrR/Of/qu/4s/+4lc40xHCQtfLAFXn3ErISkm69WUQ1cw47vnv/vv/F8rArtLbm3SmgpunbH0FRc4QgqjexEr+VwoMsN/tqlylPGDr6Wzkx1xFEo0xDN2A1lVapKg6RleC+KYZOAxDlUMwKArv33+Dn6VZVilpJ2m+19yoOfZVjbK7ocNqJf0rSklKVcVCrxqP1L4zs+qLGSNx8H5/ABRaVz+q9Sp8GqJfyVkpiZrGuBNsylmLXyZYxRKb7F5B3XuWRIqpjrTuVhqr9H4u9H13pYvrJrbfpnIZnO2EXEypVDdNTIvsalS0ySOp1BbLXHCuq4MxHMsyib6ZNasya05wOh8x5t6aY1n6rb33VeNPhJe6Tja0tYY0Tc5VwBto/Vu260RKT2dxUaX97Iw1jjaTLUYvUrZVFKofRlB1ADqFWGS6wX7/wLLcFhl9hS5gk33N692THjOzAl1X4UIpBYowt+ykDDuOazTU+rtB6KoxSYiYc5baS+2kEPa15uV4xgePNobODTSJ6aG/Mxew6R8YY9cuvyY0us5y0Yrz+Sjj/IZRxoylALiqlXvV3K1LlO+vknk+eFL0WLun78f15z4/P+KsQ9em2DbJVmg+dzZGZqMh1I5l+/dlWTifz1Dg6ekd7999w27ckXLkp48/ytTK2gjUuhGvkKfcx3FoeFRe1eTahPe+73n/7kEqc7X4dDqdKtXgtoDh5oUqpdkPI02mMsbGnZfR831lnkzzBe8XoeIsnr4biDFI0bZKOrcBciIgfB2BtBtGXNfXYy+N803NsRSxxLrmw7vdHu/Dze2Gtwf1VTdXFl3jXQCuu1zKVe6ylMJ+t1+FSMde2kDESgupWCa0y9d677mcXhl3e5GXLiImHmJgWZa1gUBUIq/T9m7V1715R2NqkzpYLW7TJQq1wVwptf7TWrta4eZynGvjUaQnHHUdfzQMA++/+VYsc22wlcVK9UwbUzlMajVStlbp7rrQZZGoqJZQKEWUa2ztaDKm7ZAi5cTf/t2/X11OquPCpH25aXWamvK1iQOJ0+lIyZlx3NF1PU12drffEWNtL1Gq9sSI5e/7e4eAdcaZqlr0pZKMm/JxqB35wzBQcuHp8d068zvWCQEpZ7puoE35URspWRme2q9uQwTUSp3brclFiSqO9yzLvCq3ttNyt4Uu87KW8ksd/d52EOTotcGLnXPs9/vV8EiHk2QraxSUEhSFqeFgKbI77e+bdOV+t2dZFgbnmKYzKcncYVUgxUBY7lxNe3jY85vf/Ib/9r/9f66AlKhPXVmfKUbGcSf8vPpC+qEj58Lf//o3/O/+o/9odU0pJULwFdC2UAS/bX0sMUob1+FhL1pJry/8D//Dv2Hc7zBKozGQEyVn/tX/8dv7LVRrzXfffcvPfvZtdQ2mRjdFzLwSy7kbq6VVIg/S9T1aW3772x9xVtK2dhK6rgNVUy7d/HLmdDqy2+15eHioR/gEJvNX//Jf0XWjzK0oEuP6ewsghhjIJbPf7+VBtWaaTkJQ3u+Yl4XHh0GiFyWGwxonyLu+DpmKMazBwnZSiHzk3j09vcPUbqVSCjEG+t0epQwpyTBlIYzcLsh/8x1NKUtT8Np8J60dku1rhn6oAzLESOmKHED9b2tWt6OUYlmWNQ+tSwTKJr3LFeAWFKL1q1rrVuTvj9Ky1XVujWamaZI+z25c9W1tldASGXZb6aliMZt2ta58+pYYNHGYGCN910tLSC7VWktHsfcLzjoe9vvquwU2zTnhvb//QpUxqGoN9/u9yHHlzHk6Vw0/SDmuQXZKBW1Yd6bNkMhV8by5j1hH6Got40RyzYi01rx7fieyXssi4aK6ZkjrtINy58gI1BdgsVaKkpsozMw6IqymazI5K633sQHYWyVykesRVblYR/wBa7TVjJ5pEy1TJGfRDSzlqqB8y+cr+kc9qoiofnPol+nEMHR03SAiMJVnJOhCxmDJSo5o2ISGbTHWWhlsXnGmlIQn0V7ovCy4LOpxLfgQJjf1rtub5dtvB7C9XwdXNLRe9Igsl8tF9MhKk52065Fq4aHgSI42a20Vq9h0EFtjV1F+YHU5OaZ6FeQlpXSdYHDrYJvbrW6VS1/zyXrkpnkS1RttGIedHNmS6Lr+i/sjtRmZLtIYY80YtX+2xLwNQG+THK1zKG0rDdbQdO7V5s7ebaHD0K/3oeWb1lj2u0O9Y4Hz5YTWkmMKAqCqspQ0yyp01UlJxBjqzyvkLITkliS0E9FXZeUYwnVQa5JctZTEPM8cj7d1G36FAKJeEXlr5R5tUYLFL8LUtA5nXVUsrw0CSkNOeD/Tde375FdL37gEFkZXmYN6tD9+/IkYJZCfp1OdTFBWUZm+F4Hxuy5UpHjyqi121euTfs7D/mEV5p/nC/M8s9tJ969SorHZ931NlKt6nBKkou2uq+3QKYnQ2tPTMyGI1q5WgklpbdaMRSnFy42aY7djRsZRighut+xewTo9q2E50zRhrVvVqpyTQMN1Du89zvVrDuuD8IoUYph0DftiuLqlYRhWBTlxJyJ62n7f09Od+bpCtzFrpNPMfTMG7Sjbyu2TuaCpohGGrNps0bzGuVpbhtGuyEGMcu+z1nUgRtWzzxlfY2RBFtzqpu4+NOOH333PL3/1C0mCa1Ry1d9kDeVQ1efVnZcdWIgx8fe/+TsulxMK6SbM9SU0jbKUhIa3JvNRuiAupzPkLIWpblgjonZ/9/uH+y30dLnQdV1F5OpMJVhzy4YytF3/krpW0MButxfQuyrAKamwAgUfveSZSqGbG3NWspUUcZ10KK5qrctSxSzuTNboxnFtQG/T6VIda9ucf8tM1gwni2xB13WMfc+H9x94eHxcMaIi72B1+g0NHIaR8/nEMAyiuqM7fvN3fwNK15YuqQDY2ul/y+f2gCGGWki6zust5fpLlFL89NNPXC4XXBX/bcF6mxV8OZ83yKBMt2tGp50K7z0hXLOSvu8xxtbZ38L6XAOMUu4fMKQqkg+t7inYbgvx+r7n22+/ZbfbEYLncjmvSnMiXADDbne12OqK/+aca2JQ1oRbEnaJgnIufP78wvF4XKt27XvuHtQ3vq3SCk3TKrneUahHUBVKNnXnSvWrc215/tJwtfvcgDGtdd1Bsx7J5lIeHh4Zx3FVkARxPXcP6lNIhEVKAII2XPVR2r2VAVTXzGQcxyu6B4zjriYCpqJ8V7Q+VmH9azAAShW8n2V3bR1jr8VKD8MgR5d739HE+mA5R2KUtGuaJs7nM6UUpkrkV8A8z6ub0FozL1eLvPav5LQaMqW+TKIFiYCuq1U1ZQhhIeVYUYaqXWbuTKj6/rd/iy4zn376HW1KZM7CuqbGvzKHVI7vtagrgmzHl8/89f/nX+OcFI60ahNp0zroWKkrFSdXtY2cxQ+/fPrIEv/fkr9WykBK8vv/z//Z/+l+C10uL/z7f/fC3xkrQg8VKMsUrJbOw85JlGPreM3QhqomGWP91//mX9PGAbb6ibyYpvWX1nmIiw+EkGqVWzqEf/u771m8Z67celXJG3ddqNGWXDt2hRVSa5v22jmBEk6fTNwRgCuluoAkRaaCfH8bzgpcp8tWDbGcYegVpXgs14nvwPoSO/Q6RvuWz+1QSoorsgDUoVJ6rXQr3TJ+UURugqWtGNQWIvWSqxsJdcawqgPiSikoXShRKOaSPNS5pDVFUypU4O2PMGiVoioKx5qZZFqgXrCVd7v4SOdqDVOWKPT0jSspRROrFEiI9YWUXKcKyGD0NmC1GTOZUpvXcbnSyHctSd5toa2OqSuYnAvr4DZdZ6C1M5aqn/MxraM5TRMoRcBqkRqRPDWXIgUnI5LuqcbRDR0E6Y3LfkMpyNLA0Eba322hxphqDVsjAJg6oFGmsNcByLUC3bnaKGckg2mW1UfBi2jiFUqtHUsggBgIIC7zFCUH7q30eSsliz2ezlXl/N5HV8nOiCgwq/Nu8nkyHa9gramNr3LMU0wr9NGOrvSNSpxq9HUynhivhKtdi7nI9Eu1nhLWRKDiZiuL7G4L1TXDcKaqrnJ9yFaCt/VYy4PJ7mqj1oeRAcbXyKpNklZaeElNzl1AtDphtjS3I0d4hVSUNOspfef+UV3pM3nDK4qpTnxeS37iBqw1dEqvQqNRi/vJWUZFGSv/3aY5y+6r1TWFnIXPi2gwGIQYHWNiXjw+JJRxqAxbDuJdFtrmZpeYUUVVLpDcyxRFOYN6tBUVs60vxOJIOdZGOxntZ1ufeM51WntNELzAKUWskWC6KdVKO3VkrpymYt0fwb1Ip5ZoLyglVNbmb+pDruEb4m4EGAOlQRcJJnQNLrSSqZQxptqLKlwjo42chMJa1KL+fUqFvuvoXFeHeOT7BwwhiPR6p9q0VzEIqYhVSG38QT3eoeodaa1xtSRBgdT0jGpJIRXxtUqriv4BUWaFa93QRamexpSq35VniDnL9bnnQlMpqJTwpWCKXdWTcy7kAjpnYk2ypZ80U4qi70z1rTJdsgkdUkR/RWmFVYaUIGuRtnXWyL2vLxNKHZhuaqAvpQ1bA4m7LrQJ9ipVsLVqJgUjiXcpZU3drJEqtRAlS22yy6vLiDXzMKbCKbWsWIpM42owidRfkriSInzdViNdlkzJ6eau/a9gjsWaN0pfskKGZjSsNhdpUu+drbTzyk+oqEK7m6VcU6y49pxKJ7DRrY5KFUUs9XtkzG4uosRstCZniaLvrt3pjKFk+UWrLl+RrgZ5MNECa5/C9Q7bUqrbCDXo4AvsyOg68rqU1bhIPUf06kMUuSCjNdrJPMRh6Jnnhene/aN5nRZQh8nkItFQziKVZ+w6bd0YsLVG0gbCUY2K0iJIWirza63f0LQ7M94H5kXA66UyOFVlrvk61NUZS+ny/QUQRQ8wV/CrVqGL5I6mjuxLcpnQRlNqBGSq9I9IxsqfNZ6RWFIhaChFFdvPq45YqmwzSsEULelbXXTMmRBzHaN7x4VaK+iBTJeUpNe3O0sr/9W8sVTZ9lSIKjPYVl+hkpP1KjzhrJG7XtrvcRQkGfAxEGJeF2e0ltg55qurufcIeoEyhednjDwcStThUmWaCLCs1gV1vcArxsic31aLSSnXinllZNc5Lm2xpp53Zy3RiuS0MbryHSqakeTYmxsB7K8IATWny1zdgLzdWGujbTqlqg/prF1dhrGC6DcOUqqXSjgQuuae1xIkQFZtwaBHOeIh1vmGDT6pv3fxd+7aL6XICM5qQFKSo5eBztoKkeg1+G/Goxmd6ilEtLumZQKFlHWGaCODaKNxFUBr+ak0GRTZyXqnrTWi1XvPhV6mWeZIxIjJtV5ShMAxdE7GB21SNq0EYTD1LrZF59J2tMh0LWPQVHSh7joUir5y7aUCV7Og2jKilIaSbpUz+rrRuS0ASKqWFmxX65TVxyl9TdCLiAO3EyA9B3qdPNAa7UCa2YEv0P9UXU2pdZhGZu4cRCSAaNqCd12ocw7vg8AllMoHKth6P61rmJD4VlV3qdSXdG0Cuna9NIZZjWpJqawS0ZKqRVJNvNeQUPI5nNGkFFHqziFgE90HSZXWzD9LflgqAL34SEylGhARbnFV7KUVjq5jimThOcsM0ytnX62ZTymNMhdp4vztfzFElnuP5dT6etRaCV/pK2oAMgS1pWE+hLpQVTuOrmBzQwVl8IZkIrIv8u+5ljmav2l4b+MvGSXpYOtWvOXzFc3srBlLzg3zKWDkCMZKPV25R0mgTAGd4xoGpiSVbmv0ivjHmFdj1fJYVVHhVjN1WqBQVccA+hBkgmW+80JDTDir0FqQvpwLMQtd1YdE52rAUKOepn9UcmEpQmLWtbmgIBNncxYZA2oZohRpJZGXkmuzUBv6KAFDG3gOoshj7+1eGvZacqbo6uuqj5OuB9amvJTTGpAXZyoVp+AaTFoVGpVSTHNAcQWmdeUyycRYWG9XKZR6dTRVwD+Vqj55x4VaY1aL2CKgUqo+GKaCyRFnhH0tXyMKrapjnWTpQ6Sg6vQBgWGMljDQOSM6DkqtKq41F5BiccprOicQS7y/e2mNOKYiATGkWmvWLF7mF/a9ANe6midFKw3KLq1uQmtyKkJ9qxxcVCYtlZpuWlCA4EsVPw4hrpmP02b977sutCHtLStKtUNYm1KPmqarljSlXIdOSbDgquFpFrlkVvdCyWKMilhmkkZa5FuModYSRlu4oIZ+5TLcdaE+xBrQV/8GKG2q+yhV1S1TspTxSykYJY3uS4jCD6p4T6XHi6q5EXjT1p8ZYiIqyVy0lhcSY8QoERf2SlXo83YE8KsW2mqjCkUscnxMjXaaY1+8+E4f4koutlY4QqEWlxSQ6xQ9Z2tCTi0e1cVfaeWC3KeUCaT19wBrXH1jlvY1c9MiOSmiirU8L5Jc1ghIrY0ky41mKpS5uKrhSJ+prgWizFAR+1yzopRTLdVf412KJpWy3sOURCW51B/Z1xaV+y60ki4aWaJ30nMWirQ156jwKUHxuK7DKE1kMwqsSEnYWiuUdeoxbnktDfnLFSxLxBpyQj3CKa1JuxzdP0aXRIyoamAK8kDWirNPlfbW7q9oUxtiTkSv14IxSgY7FiWIg9GiW5RqyKiKWsnHMcWVe6hoAmsyHqmUvKaFdwewf/v5JLORtGaZFz4dFw4PD8RF9K87gwT7NZvJKbMsQYLvGAg+kHJhvxsAYWfO88zz0xPGOZZ5IeXEfhxxnav0N00/DHi/oJRiHPfYfuCnH74XBebecbg3u/P/8J/+Sz6+vIpGX4Lf/nThOC98eLBSeCqZlAvOiUCaMWaduN586NC7WjWvLV5GSg/OOVyNqh53I9N0wafMvEgzUN/L9HalDX/977/nP/6r/z3fPg2bjsc7LlRrzePDAWcky5984ulpx8POiRCEkpJBCFVJ2Tl2/cD5cmGavRD9dwOTl+7gh90g/A+lVhXHWH3tbhzpUqKvs9eWZWG6XDhPC0NveX4QNtk0zbcGRl9BqAqhInlWZjlkeNh1aCUKjRIeijZZw3Kd0XVkJ8ImU4r9KOpWQ+fWXFaVhklJW9d5Xhj6HqVzfXkKaySsTNELoad+/ene+ro5JylB5ATFgG5EKhkKp7SMm3eVw9cES61WqFK4zEtVdzQi6eVsVdtQZGSU3xJCxQML4zBgTdPrtOx3OzrXc5oDoxOalbOW8e7DkNH0XZV/VvDhQWR6OqMxfbfKy1pjKEqsqVGVZmM9o+roO1fLETIJT2lNjJmulwFUKhd2vQw6nuZZBplrORUyckGxi1LjMargjL3/WM7z5FemWC6AMihta+lQ/tx2PUVdC0a5SN7pvQxzNNVVGNUiIpljmlMdraDqHDUtmkUhRulX0zLyPqbIDz+IJIkqUmEP9zZG+8HRWVMbfBKXOUiZvb92S+TKMAkx4TRrbGytobMyXUDGooS1mh3rFAGjFKXq01/mRUqJRnOaJsKyoJ1jXiLjw6NMHlAwGsOtVaavaNlSnOcZ7yU4mBZ5oCbN5cNVy8TkyFCVrHyIXKaJyyQsbEWtpuXCp8+vLD6KJoNWjENPLoXdMDD2Dj/P/P1vvxdtQGNqxFVV1K2QMOfltnkvNy80Z+nOP15mlpjY9Y7eGWbveTmd8VHmoknmH1m8ByVFJKstr69H/vqv/x0xpFX7ercbJKGuqsuXZVnpdjELVrQ/7FFGZONNSUQ/r22a49DfrKxxO2aUIUQBq1Eys+X98wNWCZqbKmEjJxnnd1kWxkpr6zuLcwe+/fCMdZaQEn3fyYCMqn+9zBMxXxtpz/OFl/PMN++e1nj26eHAZamDXJGw8bC/Tbjp5h3ddY7Hw46nxwPOGnZDL1bWdmKEkriZmBO2H3h8fFzdjLWOaQlo13OePX/z6++rGxHDJYF+ncdWBaJc53jY7wRmqbBmiJFQFKfZE3MdeHNj88DtZcOq9h9jJKTCEgsqgkoBnwtzLCgLEcOySNimraBHyV9I1UpeJpG5PF8mlNa8nib8MoNSnM6LzFirtRWhqsquUwo+SoPePC+Ykmrv952zlxAC58vCZVp4mSKfX14wbuCbpx3Hy8I8XRj3ByFDGZkn8fp6rFEMfPr0IoZpyczTwq4TC3yeF+a5jrYvik8nGUMWlplu3HMYO4zKhJD49HLiN3//EfjAKc08PB7Y7+49f7RkHnc9g9V0NnL+9JHXz5/41fuRYhO601iVsDqjKVxORwYn/dn7XY/LI+SICpGXzy+kX76n5Ej0Hp+zGLbZc7oEjMo1mBe+33wJ/PTpMz99PNK5gYfB8uHp56LCPN+mZ3T7vJeHB2LO7A57ftV37Pcd0xL5s5+9Z/KRl/OZOUT2w8DQS8TSd67SanQdWLNDK8W//ptf8+HdAU1GaepEPcvDYcfPQNRwlNAD9n3P0Bm+ef9M+ovCx88vfPfNOw7jwOwD8ca64c3GaFo8x/Mk5byi2I0DXWeqC7GrEMziPT/8+IlY9a1jydVgSLBekCT6Ms3ECn0qVWVDSkZbW0cKCkaUKcw+UpRCO4OucpghQ9jUW//Q56tQwJQyp8tci0yK/X4nUrEVi3VWCxNTqzpsvBMcOEUZXhOS+L/OklNgWQTDHAZBKkqWMSnCQ6ptXTULChXMtsaSFfgk465vRDu/oj7aBjemSAjga+mg3wn+o4qMly9JobUAVykXiJll8SxL4PCwl8kee0EFrLEUVaflLQuu6xAlcxGgWGqMnEqT1NToyiVsMbbV9y5JOIc/noVKrg2Xs1BjDqOlpKv6FEqzhIzrTWVQZ2zXY7te0jRnGfpBiBqwqtPtxkGkK1Fc5plx6IWMlTNFiQKW957T7GVQhso4LUoCt3xu10ophcNuJAY5hp21zF5+T2OMGGOIuTadoyg54euYhEaXm+dZUIZGIw8S/qENPsTaVi0jFXa7vcwdroi/MMbkZKX6Am6dP/oVPCOL7QrvuydKFoL/4HqMgRg1fW/XSq9IArWyn17Vb1TfoUrh3/6Pv+bnv/g5VmW6/hqvliIyIVplxlryDyFIRaASuYxRa2eFD+n+2YsUf6rAaN01XbnwxhhUBbeowHWIifM0c7xMNVSUdsiu6/nm/QdiAtfv0NpSiqDybdR1WBZCZWZLt38hVQ2Irua1uXIZwr1bny/TzOKXK7eAjK2jdmRAMXVgsRWObgz0RqFLwS+L9IMDu93It98887Szq+a9KNIJiihMb4OzjpAKU5DwMqbC6eLJtUzRZhoO985eXO2gF65srthPqrsqPWYxF3ZWZGH73lKq9rwxkmns93uWcOXd+pRYfJC26K5DI7lqSjK1cvIe76OQKK0WJpm6UvB0ra7fdaGnl88MQ4/uZfKO/CLwdTbTMi+C8QyDzPd1BrNT4BxLCPzw40+E+A6UWGhtDKoiDCpGdO/W0r1SGmcKZnAEa9b256FzTN7LFIQshapb1Vi/oq1SIJKulx1MKfFymZl9hCK+MMYgEySz3CnFdbbou3fvsNaJsNM5cYlivVMu5CUwr8PnSrXcAY3MdJIUWKNyYppm9kPHeZqumPA9F5qRwW8hZRYfmX1guszsx455CeSs6J3hfLnUwahVg95qduMoTBRnVl79NC+UFNntR1LMK4mjIe+WTEhy9HfDSClNgUeaC3KW/FTfu8iUkeglpkRnDYM19IddRQxEfCJmRe9c9anScrXfSXBwmReWeRZ1DDTOdfRjzzh2+EVGfmaUdClVFplSGh8zrnKW7K5nThCyqvVVCS/vutDT+cK7pwdy9AQvUIgPmWmeOB2POOfoO5mK9fhwIKZMX0WXXo8Xpmmic45379/LsS6Zy+lMznv2u53UV0Jk7O2qr1Bq8n18fRWs9zyQleH1eOR5P+C6q1z0H/rcLlLqPdOyoK2M9IohMDgxINKMlwhRRg4p1BcdTz54jIZv3z+jSuH1OKG1Yuw7ckr0dWbEbugxZOLpE9Pric8//MD0+SecUTiVCfMZkqSCKMVlWtD3joyU0qt8R4iJcRzISTKaw35PTJmHh4NY4lqVni6TjLbNWXj3fYeOiaHr+PD8gJ/OXBbP6XxhiIHjpQ7GcAPH04RS8O5hANNxSQmVE8PgsFaxzAs5Z376+Pmm5/+KyQMShvkQ6Yeel+OJz8cLXeeqmLeQNlKMvBxPpCQFoqFz7MeeHCPzEuiHgf0g2kV939csJ8mU2hQZh57d0zO7px3GKZ4+fEes8iUxBo7HE6/Hcy1DtnkVd1zoL777RsZhIkSp3TBIG4gVsVCtFalKRLNpgtVaM1d1jCZqmKv81hI8PgY6J6NOXOXfa1XoeuHun88XUDKx3VlD8gtWSQt2iOn+0tB//9sf+Pz5lePrkc8vr6RSGLuOzhoZmqGFFjMvC6FqiPW9VKsvF18JUYGX16PQ4ZD42S8epS0PDw8yYaSIDPXpdNoIfQdyqapy1q4EZmP1/eujKcy8LnA47Gg61LFAQhHrmy1KIqRSCqpkzqcTUHh4OBB9qFz465xSY2TMwuvrC2PfCxCuRZZEuvIE/e2dhSK48TD2QlaupEp/b1z33bsnURFvtLacOb58wqnnVRdlGAeWywWRgi7Mi0yHRVtUjjw9PwnVDnlR0sMiSo8pevbjjsfdQPITC8LNHyvY9vLyIlotORPDwmWasXN3/+FTj0/P4gr6TO8cp/OF4D3H4yspyxzQzlr6YSCGyGU6VwanYTqfyTHw8HBA5nyLChUlEUKg6zWX00Waa58feH5+z8fPf8M8zUz9gFG7Cn/2qCgJwdAPVY35zu7ln/0Hfy70VORuHY8n3n94x9D3TNNU6XGZbz48r/pFjSApghKFp6cn5iq0VhBW5+Gwk7zSB7q+Zxw6cs785X/w54CMsU8x0nWaYRjXAvLlcmEYx6qcfMeF/smvfo5zjmmaiDEyDB1/8ie/IMYocySA8/lMzpnz2TDPMx8+fFhluZquWIxxFV67XC40BfOm3LhVVW6ssO+//57n5weRLqgiiY8P31RBxTunacCqEldKYbfbUUqpym5lfcCPHz+uXL6rpJZeF9P0i4B1ckDT6pzneaXUNJ1BrTWHw4EQQu3U8FV8WLMsy82Sll/VhDfP88rza6Iu7Y60X5pSqqL5Mv9Ba72qk6cktVHnHJfLhSb1A9cuqFY9X5Zl1b5vanLthfX1uqSUuNx7BH1z9m1n5F6W9UHaMdvv93jvqzDwdWebVmBTgHt4eFglu47H47r7TXuwifY3Cnrf91wuFwlBQ+ByuazdFndd6PYotcJsCIKWn8/ndWRJ18ncXmurKHgt7LaRYU3NtS2gHcU2masdy+3dNcas+oJN9LDhvHe3uk3Wro0+GIZhvSftQUMQfU2RzAu0CR5Nq7rve5o2Wfv3JpLYju0wDOs9br+v3eH2AtvCHx4ebg4Bv4rd2QZPybwW+dY2KGNZltWgOCeKFw8PD6txaRzcxj9on8fHx9XIzPO8XoOm4tp13crCbjLS7ersdjv2N5b2v4oL2HagHdG2Y1pLreTh4WE1EO1+tZ1pX99cTbuTOWd2ux1DjWPbiQHWe98s8+FwWI92+7q7GyOt9XrntkagPfA4jjRN+rZrbZHA+n1A1dl1q4zldgJe+552DdpdbgatHfPGDb71jn7VOLFhGNa4dp5nlmVhWZYqNVlWSwmsd7JZ2o8fP673uXF1gY3ieRPyT+t9b8qv27ELMignrWnfdkzDXRbajh/IfZ2mabWiwBcjitouth1rDyfC33m9w+2FtDs8zzPeez5//kwTLG0vpFnd9lLafW1R2R/6fJUfbdZ2ay0BjsejBOddV6Wc9+vOG2N4enpa/WZbvMiALKtweAse2glpL2OqA6v2+/16ZZpR3Gp83m2hzdQ3EdF2T9p9aw/QBlm0cX1tUTLIRo7ZVoy/LbLtvLWWd+/erS+uHeGUROz0+fl5/b3byOxuC92KAzcfGEJYF++9ZxzHqn7e5ECuTDDvPa+vr+sRbEf+xx9/5PHxcQ04tne8veAQAsMwrP65vdCnp6c/TmQErPfj2oRz3e23L6R9X3M1LXxb+7hr8O6c+2KHjTFM07Te+2VZVou/Hajx8vJy/3aQFrk043E8HhmGYV3kKknZWh9rbNtCO6XUFxFT3/fM87xK0za3ISNPxNUcj8dVh7cd16Z53Y7t3SOj9mZXDeyNMZqmiSbd/lYRWWu9pmWrWnk1bA01aD+/3e328trp2e126062OHgbjt51ocAX0U3f9+vbd06w3WYttylXW0Szwu2/m7vaBgPbzAiuMphbd3I6nVab0PzqXReaUmIcx/UXtmPTjIoMpolfxKnNWrYdOB6PHA6H9eHbz53n+R/Mp2g/q73QdgIEQQw8PT3x+vp6/8gIWKfdjeO4yqe3OLdBJM2lNGffspnD4cD79+/XI95i4vaCPn78uKZdu91u1cRexSs2+WwLLvb7/f2t7jiO65HS9ei2N9+sZrPEl8uFZVnoum51Rc2aHo9HplrEPZ/P0t1b/+719fUL6KUF+u1397WDoh3beZ55fb1tjvdX7egaFVXr22LZbaC/LAsPDw//IAuZpmm1pofD4YtspfnJhwcZldACixZytpfaTkNLIG6Nir5qoVsX0gLv9hDtE2NkHEe6ruP9+/dSZqh4T0MT2oL6vueXv/zlGmm10HBrpFpU1Ha373v2+/2a5TTx/1s+XxUCtk+LU9tDtbiz7UQzItvsQ7BeyTbev3+/uqeWvTSX1L6+3futYdqCYw1BvPsdbQ+yRQFbDNvyxLYD7Yg1dKAZlpaetWC+WdRtlNWMWwsk2i43a59S4uHhgefn5/Vn3XWh2yR4aw1bpLSd/7IN+5qraS5lG0goJcPmSilcLhd2u92amVwulxUmUUqttmCbDu73e06n0/0X2n7pFkFo/nJ7f8/nM+M4rv5vnQUDX7iNBk63gN17v8KoWwx4e5qANUb+7rvveHp6uv9C24wVYA3VWvTTjhmwplgN8mzGpb2gtivtoYdhWF1UKYXj8bgiCO0lNpi04UYN593tdvddaDt+Lchuf9YW2+5mCwnb3Wyo/LaW0kK9t4ux1vL+/fvVjbWvu1wua5DRYNZmBBsCcbeFtjvYQrqtLMBVjiCsvq+VMECO6+l0Wu+fjBfar7Gqc251U+04txe4fcHNRmwh0D9Kkal9tmj69ui2nW33tlnKxhtq/93u9/Z0NLikvcC2yJYMtN83TdMXkdjLy8tNz3y7FFfN7JtbaT7xLUDWFtXMfstcGlLYkub2s9qdb0BX+/N2VKdpWiHUVrh6eXn5Asm/5XP7TKauW/1WW1w7Qi1Bbpa1waDAZjTRdbxQ+/4tyN2+r6H+rZJmjOHl5YXL5cKlDsBqp2D7Qu+20K2V3OagwBdRUEPymqFpsWnLZRuy3lxOw522EEkL+lv46L1fv6/F0jlnXl9fbzZGXzEJz6xGo8WnLexrUU5zKe3rW5G2Labhss2ijuO4BhwtutpCmsuycDqdOB6PLMuyRks//PADHz9+/OPsaNutLYK3jU/HcVz9ZrOS21lN7Z41dGCLsjfkvd3NLd7bXurpdFqPfEvxtpHW3Rbajuy2dtn3/T/wgw0wO5/P6wK2IBqwxrfbpLphug0nbm6qvayWmjXb0HUdnz59urkkcfNCf/rpp/UutvFEfS9zu5VKVRarTgeohMT2cl5fX9dyPDSkQmCTZqVXADyIQnIbtXK5TLy+vlBoYk6GEPz6s1u6eLeF/lf/9f+Nx8cnUTCnGicFIsZd5dStTBOIUVhiLYvJuZUL7UpTB+kqXFloMRJ8WCcQtFHYoq6TNg20bRaU6PHeHRyb54W+l0mywuMzddDFVfo5pStK32LTa3SkSenL8n1K83oVQNqk5UiLjfQ+XNELebvrkI6Ucs1Z76zDYK2lqyjdy8tnPnz4Zm1p3PIatsH9tvai64CqFhk1v7oNKVvE1HSy23Dylu61lwTXIcvzvRtl25gDbQz7w2Ft9Hmbp7bPdSZTQyeu9ZgWG2/z2PbZWlE5FW0Se/7ihV5z3zszx7aUmDbNrh3b7QO0O9QW1I5lW3T7+hYObitiqapsXIXDRTqoXYO3ycTXTKv8isjompY1SLL9sy1AIQaqLXBLutq+kG3JoZSyDpRq8ymsFTGYNgSy7Vo7OVt04+4liWYgWoS05Qq1T6lNru3r2kO0BW1nRGxfGLDqYjd/HGKUhiBzjZHh+rK3J+OuC20919sFbHe4/Xd5Y6Daot6WFtvfb1G8snlxRhuUuV4FuAoQt9OyLWbdbaHW6C8WtC3Utgdpu9YWunU12ze/PXLbY9j+G1jv5hZKebu4W4/tVy10v98zDsM68GKbdm13Zfvgbxe9PQnbo7c9zu3vG5K4NWxv72R7Ebd8bn4lLQ/ccnu2CEN7qLel+a10czNg2wdvn2u0dK2otZj3rT3YVtTvfkcl5FO1vzP9gx3Yvtm2Gy0wf7vz2wxo62tjSuhNmXH7u7dHu+FMf5Q72o7b1uK9jWzegtRwLfFv/WXLQbc/u41ZaJ+3J+Otf97ai7sutL35LSKwjYjeOvW3Ral2d9tubRP0xmvYWmjZ0S2N1a4vuoWDLd2760JTxYTaQrdvFb6MUraY0Fv2yvZYtli4fWIVFIc2VbaOvA4eHwxdXWB70e003XWhwBf37m0gv7WyLTx8y+zavoztMS+lVPFR1j9Tuc2mEGWAnApLCZQ6+6kF/nevphlj1yO39Wdvd/ftf78tz2/vWvs0tMLVP08pyfj5nEkp4pxhmb2IrHUD8zJLgo6ilD9CmmbrAvtOBAsbHaYtfhuLbn1k+7RAfvv3W8PWXkKDVsZhwNkqP7uT3yPT3A1GSx/c3REGpWqpXakVBWgAVrtr20D9bdDd/ry5lob4besxzU+3lwHyO6dpEp1ALeOLmiCqDprd7s6ysznLbJdtIdha+0VgDtd4d7v43xf/vg0B2//flvl9uO5YO+I5J2lyr4DZLZ+v4DBQR5tc+UHtl5s3heH1h28C9y056u1xfpvAN5Sv6zr6rv8CYZDBy/L1i1+4VZH/K4SbAotfiOnKzVsXy3XIOHxJgmyQZ1tU85stiMgbA9Re3DYIacd8WzlbvOj5jsMfqWWrPWyLPa2VcQjGmC/mubQHjjGuScDW8rZTse2F2Sbn20JWw3rbVQkh0He9JOeblPFuC23kizXiaUdNi3Jqu1PNd+acCbGyVKjaJvrLpFxvvq/Fr203G8zSXmh7cZJcWGTCQfrjhIAt/JJdlPEBbWrI1mquRdyqv/lW/aK5kJQSKScWv8gELSUt0bEWltrPkKaf6xSCUsRANUXXuy60VctKEeW3FX17Y1XhGmg3xTjv/doCud2hnEW3IepIKmnV/ZSvE5X0ENLqbnLZDFLWMlHv7tnL9iMLESDsbZSzrYEKYCZYUjNErcq9rXGWht12rRdGo5QINLXRDDllgq91FtWyGsWtyhpfNdhmmzumJFJ1LetoMfAXi6yxaLvbrTS4RQ4BxuFaPmzDp5BRMFJ9q3TZlSQiQxa+SP3uttDFL6JUXKtX26bZZlSaoYoxcjqdQcHDw2HlBbVWr23KBlciyJfYcbWoDZAzAFHcWMwUGsZ75zs69P16H1vtBPgiGADWMO/dO7cucBvDthOw/Z5tHtsWuQ0hV1bpps0LvoRy7rZQmdxxPX7rn9dd3CbO7Zg1P7mNmtrXblO09vLa925/Rnt525y2/Z72O++60LR5iMbK3Oagv8/MNzrONjDYBv4tMd/uTAsStvag/f9atZPSxR/ljrYHews5bq3uNk3bQi7b0uIWTgHWIL5lLTnneg/jetTb79gCcKXk3/ty/79eaBsVtrWYbYfe3rv2UlpXk1Jqpba9xXCbX20BQtvZt4n8NmJqPn2LPd1toTnlVYcBrtFNi5jaA7eHkJdjvviarRFpL6vtZIyxDt+4Wt9t2zR8iR3LEIA/wnSQxXuORxF5eSsIsU3dtg/4+2ol2zh3m7msriWn9e/bn7WMR75WhGVyhVnuvqOua0yRq9nfAsvbjKT9fdPstObLluZmbLaLbV2K+91+PcJtEe1rQhC56PYSUrI339OvBLAl7ILr3dkewy3wlbOMJiqpUPS15NeOWrPe28ChaYNucaNt/UaoAaIZuHVXd11ow3qa5WuL3Bqk9gK2mBFcxSpa+Ncw2cbjBdbmnpzrELlSmCuDu72gZgybdd4GLndbaOvya2TgbcPcW3LUtkWkuY/2ghoncNto0JijLR9tf1ZKWVG+trAGq5RcJMi/tzT09qFbc44MdrwmzjFFduPui/u7DRLe9q+1+Lf97G2s3HZ3e0/bP733fP70E/vD4/37XtoP3KJ7tkY8WwilxbrWGHnrMa4DzZvhaD9j60u3AHeLfX9fNaBZ9nfvP1QU/87GqB2rdle2aVn7NA5955xMvNM1RFN80UkBV75QczltN5tr2oZ77Wpsg4hGj/ujJN7bX97+uUXc10WsNZEaEnKNb9tuNZeytdxt4e3nbsPDLfLfTtEfJahvb3l7vN4em+1DtAHIWovQWkvc20K3mco2Vt7u9BYO3X7NltZz94Vu702zhtuC01vOQZslrrTC6lozKdedeVtmbH65pYFvw8ht6QKu4ePdcd1G5n8LMG93pPWKvk3E5cmgxOvDbndmtbYpopJaXcg2mtru6nanb37+W7+w7UL7bDHet5by99279t/bOkt7gSu5uI7sbNnKFqrZfm/7fM1Cv4pTv83839Lj3oZk25Cw3bttdLPdrRYxNVr5NpaGf7iD22jo1qD+q9RvmiXctni0xbfFbHe5PdRbItTWpWw/Wyvefta2TNH+7G26d8vnq1kp7Ze2B90q2WzLEdsH3/rOt4H4dtfeVtXeWvWt5X276LsttP3grQ/cFnObuzmdTjw+Pq473GDRtjtvr0Cz2G3H3/rk9jvb/7d57q1J91ctdNvW3DoaGpy5De5Tytc2j5yrgP6XpfxtsLFd7Dbz2RI9tsZoS+dp/37XhW53Yi0i1QeEq2rj6n5aFKOkXtI0sdsDN8vafnb75/b+tZSuLXaLE7Wdvn+RKUVy+pII1RrkUkpfdDgBhBqHtodV6ks63NZVbGPZbdCx/fetW9qGgneHUrTSuN59we3ZEiG3d03rOtC8fs32YdtL2lrp7W61F7HtdduC12/j27sf3a2DbwXZ9ka3NdHVt6ovqafrC9jAKdud2rqVty2Tb4FqyWtvD+i/aqF9339xxJoraL/4raV8ixS2O71F9pu72WYmcIVptndQbYwafJk23vL5KmWNtzDltYz35cNtX0BbVDua2zu2ffDtIlvk9Zbis/XjzZjdHTNqb//3MTUbmLW9r9s0ahtQtAdrhmZLwNqGfduw8vf9/fZ03HWhW4OzRQC2i/gCz90YoK0Vbe5oe3Tbvd1CoFs0Y/vZLrwBaHdd6Napb0OwbQC+BbF/n6vYvjT4sr7SXtY2XPx9cfU2lr51kV+10G1++PYobnPGLY9vewfb17e/24Z92zi3RVXtBLXv2V6Zt8jiLZ+vm7K1cSVv79r237dHsT1QMx6/7zQ0o9M+2wRia6S2frVdga2E7f/c56uaB7a78TZf3D7UNsR7m0ptE/DtMdze6S12tN3FphiwzYdvtbpflY82dH0btWxR+PWH6i81BFswsQ0CtpHU26T998Ek7eW1Bb5FG/7Q56t6vNsi4GostslyW/y2UT2XTN/1XyTpbxe/zWHbgtvve/siti/gaxZ7e320diS02sn2mLXFbZPyZVlksDFqdRNvCR3tz7z3Aoyh0JVS12LqtuB2eraJQXvhd12ovDlJuBuZcXtPmu5mW7BzDh8C1nwpK7sN7daFBk8pFWfKmVAHn29TNvHHBZCBOe163H2hjd05V9XjBk92uvsCCINrXtlrocg167rFb7+MdU2d7VSDf6W/wH1lse3FyHRaaLv8R2rwaQ0EKcngC1/CP/CDOWd89admgyJsLeQ2g+kaPQewm9BvixpaK30xMQakl1V2+O5jOeEKp2hTm+Q2Affv85GUsg59awl4u79f5J5JBjmCIr8JKZstkLuvKMXUFI31/3df6Bcw5Ib5tcVdr9Y1E0NEp7SSmNsObSmx1lpKFZlQ6suOxAbCbROAEJtvbqn9nRe6JVMZbdY25bcQZQvLhF76pSjE23i1/dzGSjPmGgA0Jso2g4kxCuuzXGPfrrvzlK3f56/exp6wgTtg7dVun39YE9VcLpOwrxG+4Tb+3d7j9rPbwNa287emal+VprWMpPH13pb8VpfRjJH08X/hOxtRQ+ur2nEuGY2myY5sA4stLNqwY2MUIeSbDRF8xY5uI5VWNWv/vd3tq3KjGKNxHFZr3O5c4yEorTHWrAap0fDaZ5v6baEascTqi+f6Qx9VviZg/F/x56tkZ//X/Pmnhf5j+/zTQv+xff5pof/YPv+00H9sn/8Jfbw3DVqJMwcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of non-crack images: 8404\n",
            "Number of crack images: 8404\n",
            "Epoch 1/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 404ms/step - accuracy: 0.7194 - loss: 7.2970 - val_accuracy: 0.8322 - val_loss: 0.1048\n",
            "Epoch 2/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 391ms/step - accuracy: 0.8632 - loss: 0.0860 - val_accuracy: 0.9311 - val_loss: 0.0478\n",
            "Epoch 3/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 386ms/step - accuracy: 0.9119 - loss: 0.0576 - val_accuracy: 0.9560 - val_loss: 0.0343\n",
            "Epoch 4/10\n",
            "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.9377 - loss: 0.0463"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-cfcf30ced0a6>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Train classification model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m classification_model.fit(\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Pass validation data here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    343\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     )\n\u001b[0;32m--> 345\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    346\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_ds, _ = dataset.get_dataset(split='test', batch_size=32, task='classification')\n",
        "loss, accuracy = classification_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute additional metrics\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    predictions = classification_model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Non-Crack\", \"Crack\"]))\n",
        "\n",
        "# Generate confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "y7wFTv0LkckU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f3b361-97c0-4b05-acb2-0166bc47ddea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 200ms/step - accuracy: 0.9167 - loss: 0.0727\n",
            "Test Loss: 0.0664\n",
            "Test Accuracy: 0.9180\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Crack       0.63      0.82      0.71       212\n",
            "       Crack       0.97      0.93      0.95      1483\n",
            "\n",
            "    accuracy                           0.92      1695\n",
            "   macro avg       0.80      0.88      0.83      1695\n",
            "weighted avg       0.93      0.92      0.92      1695\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 174   38]\n",
            " [ 101 1382]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### conclusions\n",
        "surprisingly the augmentation of data did not bring the improvement in the accuracy or f1 scores for both classes, it seems it has overfitted to the training set as it was receiving very high accuracy there - and worse on validation and training. As expected it increased the recall of the non-crack class, but on the other hand decreased it's precision , overall the model not utilizing the data augmentation proved to perform better on the test set."
      ],
      "metadata": {
        "id": "Cd9xIsfLy7RQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUiVudX-FmlS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unet model\n",
        "here are defined the unet and unet++ which will be mainly used for the segmentation but we may also try using it for classification\n"
      ],
      "metadata": {
        "id": "bd0Be_sE5X7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''with the batch normalization'''\n",
        "def unet_model(input_shape,filter_number=32,segmentation=True):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Layer converting the picture into grayscale\n",
        "    lambda_layer = Lambda(lambda x: (0.21 * x[..., :1]) + (0.72 * x[..., 1:2]) + (0.07 * x[..., -1:]))(inputs)\n",
        "\n",
        "    # Encoder phase, downsampling of the picture\n",
        "    d1 = Conv2D(filter_number, (3, 3), padding='same')(lambda_layer)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "    d1 = Conv2D(filter_number, (3, 3), padding='same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "    p1 = MaxPooling2D((2, 2))(d1)\n",
        "\n",
        "    d2 = Conv2D(filter_number*2, (3, 3), padding='same')(p1)\n",
        "    d2 = BatchNormalization()(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "    d2 = Conv2D(filter_number*2, (3, 3), padding='same')(d2)\n",
        "    d2 = BatchNormalization()(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "    p2 = MaxPooling2D((2, 2))(d2)\n",
        "\n",
        "    d3 = Conv2D(filter_number*4, (3, 3), padding='same')(p2)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "    d3 = Conv2D(filter_number*4, (3, 3), padding='same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "    p3 = MaxPooling2D((2, 2))(d3)\n",
        "\n",
        "    d4 = Conv2D(filter_number*8, (3, 3), padding='same')(p3)\n",
        "    d4 = BatchNormalization()(d4)\n",
        "    d4 = Activation('relu')(d4)\n",
        "    d4 = Conv2D(filter_number*8, (3, 3), padding='same')(d4)\n",
        "    d4 = BatchNormalization()(d4)\n",
        "    d4 = Activation('relu')(d4)\n",
        "\n",
        "    # Bottleneck\n",
        "    b = MaxPooling2D((2, 2))(d4)\n",
        "    b = Conv2D(filter_number*16, (3, 3), padding='same')(b)\n",
        "    b = BatchNormalization()(b)\n",
        "    b = Activation('relu')(b)\n",
        "    b = Conv2D(filter_number*16, (3, 3), padding='same')(b)\n",
        "    b = BatchNormalization()(b)\n",
        "    b = Activation('relu')(b)\n",
        "\n",
        "    # Decoder phase, upsampling of the picture\n",
        "    u1 = Conv2DTranspose(filter_number*8, (2, 2), strides=(2, 2), padding='same')(b)\n",
        "    u1 = concatenate([u1, d4])  # Skip connection\n",
        "    u1 = Conv2D(filter_number*8, (3, 3), padding='same')(u1)\n",
        "    u1 = BatchNormalization()(u1)\n",
        "    u1 = Activation('relu')(u1)\n",
        "    u1 = Conv2D(filter_number*8, (3, 3), padding='same')(u1)\n",
        "    u1 = BatchNormalization()(u1)\n",
        "    u1 = Activation('relu')(u1)\n",
        "\n",
        "    u2 = Conv2DTranspose(filter_number*4, (2, 2), strides=(2, 2), padding='same')(u1)\n",
        "    u2 = concatenate([u2, d3])  # Skip connection\n",
        "    u2 = Conv2D(filter_number*4, (3, 3), padding='same')(u2)\n",
        "    u2 = BatchNormalization()(u2)\n",
        "    u2 = Activation('relu')(u2)\n",
        "    u2 = Conv2D(filter_number*4, (3, 3), padding='same')(u2)\n",
        "    u2 = BatchNormalization()(u2)\n",
        "    u2 = Activation('relu')(u2)\n",
        "\n",
        "    u3 = Conv2DTranspose(filter_number*2, (2, 2), strides=(2, 2), padding='same')(u2)\n",
        "    u3 = concatenate([u3, d2])  # Skip connection\n",
        "    u3 = Conv2D(filter_number*2, (3, 3), padding='same')(u3)\n",
        "    u3 = BatchNormalization()(u3)\n",
        "    u3 = Activation('relu')(u3)\n",
        "    u3 = Conv2D(filter_number*2, (3, 3), padding='same')(u3)\n",
        "    u3 = BatchNormalization()(u3)\n",
        "    u3 = Activation('relu')(u3)\n",
        "\n",
        "    u4 = Conv2DTranspose(filter_number, (2, 2), strides=(2, 2), padding='same')(u3)\n",
        "    u4 = concatenate([u4, d1])  # Skip connection\n",
        "    u4 = Conv2D(filter_number, (3, 3), padding='same')(u4)\n",
        "    u4 = BatchNormalization()(u4)\n",
        "    u4 = Activation('relu')(u4)\n",
        "    u4 = Conv2D(filter_number, (3, 3), padding='same')(u4)\n",
        "    u4 = BatchNormalization()(u4)\n",
        "    u4 = Activation('relu')(u4)\n",
        "\n",
        "    if not segmentation:\n",
        "      gap = GlobalAveragePooling2D()(u4)  # This layer reduces the spatial dimensions (height, width) to a scalar\n",
        "\n",
        "    # Fully connected layer with sigmoid to predict binary output (crack or no crack)\n",
        "      output = tf.keras.layers.Dense(1, activation='sigmoid')(gap)  # A single output for the whole image, with a sigmoid activation\n",
        "      model = tf.keras.Model(inputs=[inputs], outputs=[output])\n",
        "      return model\n",
        "\n",
        "    #output layer, sigmoid to map the likelhood of belonging to given class\n",
        "    else:\n",
        "      outputs = Conv2D(1, (1, 1), activation='sigmoid')(u4)\n",
        "      #outputs = Conv2D(2, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "      #the finaly binray image , iff  mapping , belonging to which class was bigger\n",
        "      model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "      return model\n",
        "\n",
        "mod = unet_model(input_shape=(448, 448, 3),filter_number=16,segmentation=True)\n",
        "mod.summary()"
      ],
      "metadata": {
        "id": "gORSqg2U5it4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70b4b2b2-2a87-4b25-c2fd-d6012bd183c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │            \u001b[38;5;34m160\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m64\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m2,320\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m64\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m4,640\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │        \u001b[38;5;34m590,080\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m131,200\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m295,040\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_10             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m32,832\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_1[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m73,792\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_12             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m36,928\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │            \u001b[38;5;34m256\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_13             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m8,224\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m18,464\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_14             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │          \u001b[38;5;34m9,248\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │            \u001b[38;5;34m128\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_15             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m2,064\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ conv2d_transpose_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m4,624\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m64\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_16             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │          \u001b[38;5;34m2,320\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │             \u001b[38;5;34m64\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_17             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m448\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m17\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_10    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_10             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_11    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_12             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_13             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_14    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_14             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_15    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_15             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_16    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_16             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_17    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ activation_17             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,946,705\u001b[0m (7.43 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,946,705</span> (7.43 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,943,761\u001b[0m (7.41 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,943,761</span> (7.41 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,944\u001b[0m (11.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> (11.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unet++ model"
      ],
      "metadata": {
        "id": "cbkYGa805r8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_plus_plus(input_shape,filter_number=32, deep_supervision=False):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Layer converting the picture into grayscale\n",
        "    lambda_layer = Lambda(lambda x: (0.21 * x[..., :1]) + (0.72 * x[..., 1:2]) + (0.07 * x[..., -1:]))(inputs)\n",
        "\n",
        "    # Encoder phase, downsampling of the picture\n",
        "    d1 = Conv2D(filter_number, (3, 3), padding='same')(lambda_layer)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "    d1 = Conv2D(filter_number, (3, 3), padding='same')(d1)\n",
        "    d1 = BatchNormalization()(d1)\n",
        "    d1 = Activation('relu')(d1)\n",
        "    p1 = MaxPooling2D((2, 2))(d1)\n",
        "\n",
        "    d2 = Conv2D(2*filter_number, (3, 3), padding='same')(p1)\n",
        "    d2 = BatchNormalization()(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "    d2 = Conv2D(2*filter_number, (3, 3), padding='same')(d2)\n",
        "    d2 = BatchNormalization()(d2)\n",
        "    d2 = Activation('relu')(d2)\n",
        "    p2 = MaxPooling2D((2, 2))(d2)\n",
        "\n",
        "    d3 = Conv2D(4*filter_number, (3, 3), padding='same')(p2)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "    d3 = Conv2D(4*filter_number, (3, 3), padding='same')(d3)\n",
        "    d3 = BatchNormalization()(d3)\n",
        "    d3 = Activation('relu')(d3)\n",
        "    p3 = MaxPooling2D((2, 2))(d3)\n",
        "\n",
        "    d4 = Conv2D(8*filter_number, (3, 3), padding='same')(p3)\n",
        "    d4 = BatchNormalization()(d4)\n",
        "    d4 = Activation('relu')(d4)\n",
        "    d4 = Conv2D(8*filter_number, (3, 3), padding='same')(d4)\n",
        "    d4 = BatchNormalization()(d4)\n",
        "    d4 = Activation('relu')(d4)\n",
        "    p4 = MaxPooling2D((2, 2))(d4)\n",
        "\n",
        "    d5 = Conv2D(16*filter_number, (3, 3), padding='same')(p4)\n",
        "    d5 = BatchNormalization()(d5)\n",
        "    d5 = Activation('relu')(d5)\n",
        "    d5 = Conv2D(16*filter_number, (3, 3), padding='same')(d5)\n",
        "    d5 = BatchNormalization()(d5)\n",
        "    d5 = Activation('relu')(d5)\n",
        "\n",
        "    # Decoder phase with Batch Normalization and deep supervision\n",
        "    def decoder_block(up_input, skip_input, filters):\n",
        "        up = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(up_input)\n",
        "        up = concatenate([up, skip_input])\n",
        "        up = Conv2D(filters, (3, 3), padding='same')(up)\n",
        "        up = BatchNormalization()(up)\n",
        "        up = Activation('relu')(up)\n",
        "        up = Conv2D(filters, (3, 3), padding='same')(up)\n",
        "        up = BatchNormalization()(up)\n",
        "        up = Activation('relu')(up)\n",
        "        return up\n",
        "\n",
        "    u_01 = decoder_block(d2, d1, filter_number)\n",
        "    u_11 = decoder_block(d3, d2, filter_number*2)\n",
        "    u_21 = decoder_block(d4, d3, filter_number*4)\n",
        "    u_31 = decoder_block(d5, d4, filter_number*8)\n",
        "\n",
        "    u_02 = decoder_block(u_11, u_01, filter_number)\n",
        "    u_12 = decoder_block(u_21, u_11, filter_number*2)\n",
        "    u_22 = decoder_block(u_31, u_21, filter_number*4)\n",
        "\n",
        "    u_03 = decoder_block(u_12, u_02, filter_number)\n",
        "    u_13 = decoder_block(u_22, u_12, filter_number*2)\n",
        "\n",
        "    u_04 = decoder_block(u_13, u_03, filter_number)\n",
        "\n",
        "    if deep_supervision:\n",
        "        outputs = [\n",
        "            Lambda(lambda x: tf.cast(tf.greater(x[..., 1], x[..., 0]), tf.float32))(\n",
        "                tf.keras.layers.Conv2D(2, (1, 1), activation='sigmoid')(u_01)),\n",
        "            Lambda(lambda x: tf.cast(tf.greater(x[..., 1], x[..., 0]), tf.float32))(\n",
        "                tf.keras.layers.Conv2D(2, (1, 1), activation='sigmoid')(u_02)),\n",
        "            Lambda(lambda x: tf.cast(tf.greater(x[..., 1], x[..., 0]), tf.float32))(\n",
        "                tf.keras.layers.Conv2D(2, (1, 1), activation='sigmoid')(u_03)),\n",
        "            Lambda(lambda x: tf.cast(tf.greater(x[..., 1], x[..., 0]), tf.float32))(\n",
        "                tf.keras.layers.Conv2D(2, (1, 1), activation='sigmoid')(u_04))\n",
        "        ]\n",
        "        model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "        return model\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(u_04)\n",
        "    # binary_outputs = Lambda(lambda x: tf.cast(tf.greater(x[..., 1], x[..., 0]), tf.float32))(outputs)\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "fZWjfJ7x5ttW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The unet model for classification\n",
        "\n",
        "usually the unet model is used for the semantic segmentation, but maybe we can try utylizing it for the purpose of classification."
      ],
      "metadata": {
        "id": "zAfKG5w53nY9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "rJG4bfGeDvx3",
        "outputId": "5fffa0bb-4c1f-42f8-e912-5693ed5ab138"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'unet_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-942196c80c71>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Build simple binary classification model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclassification_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m448\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m448\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilter_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m classification_model.compile(\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unet_model' is not defined"
          ]
        }
      ],
      "source": [
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "train_ds, val_ds = dataset.get_dataset(split='train', batch_size=8, task='classification')\n",
        "\n",
        "# Build simple binary classification model\n",
        "classification_model = unet_model(input_shape=(448, 448, 3),filter_number=16,segmentation=False)\n",
        "classification_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.BinaryFocalCrossentropy(\n",
        "    apply_class_balancing=False,\n",
        "    alpha=0.25,\n",
        "    gamma=2.0,\n",
        "    from_logits=False,\n",
        "    label_smoothing=0.0,\n",
        "    axis=-1,\n",
        "    reduction='sum_over_batch_size',\n",
        "    name='binary_focal_crossentropy'\n",
        "),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "classification_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,  # Pass validation data here\n",
        "    epochs=10,\n",
        "    callbacks=[epoch_early_stopping],  # Use epoch-wise early stopping\n",
        "     # Use batch-wise early stopping callback\n",
        "    verbose=1  # Print logs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvRtyUaXD1Av",
        "outputId": "278e9a65-ca01-47fc-fbcc-277db3362328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 1s/step - accuracy: 0.9257 - loss: 0.0277\n",
            "Test Loss: 0.0301\n",
            "Test Accuracy: 0.9198\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Crack       0.70      0.62      0.66       212\n",
            "       Crack       0.95      0.96      0.95      1483\n",
            "\n",
            "    accuracy                           0.92      1695\n",
            "   macro avg       0.83      0.79      0.81      1695\n",
            "weighted avg       0.92      0.92      0.92      1695\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 131   81]\n",
            " [  55 1428]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_ds, _ = dataset.get_test_dataset(split='test', batch_size=32, task='classification')\n",
        "loss, accuracy = classification_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute additional metrics\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in test_ds:\n",
        "    predictions = classification_model.predict(images, verbose=0)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend((predictions > 0.5).astype(int).flatten())\n",
        "\n",
        "# Generate classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Non-Crack\", \"Crack\"]))\n",
        "\n",
        "# Generate confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### conclusions\n",
        "\n",
        "It didnt perform bad, but it was worse than the  earlier simpler model, likely because it is not the perfect architecture for classification"
      ],
      "metadata": {
        "id": "LdleECIg7Vx6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP43ovDuctMs"
      },
      "source": [
        "# Semantic segmentation -Todo\n",
        "Here the semantic segmentation will take place, firstly we will try the unet model and une++ models trained from scratch .\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TODO\n",
        "-trying out these loss functions, thinking/trying the parameters in the focal loss function - alpha parameter, which determines which mistake to penalize more - predicting crack when there is no crack , or predicting no crack when there is crack. probably the predicting non crack when there is crack should be penalized much more , since model tends to predict non crack everywhere, and there is much more non crack pixels\n",
        "- trying different batch sizes, 1 probably to small , 32 the ram may not be able to fit but maybe it will be ok also , but maybe something between these number\n",
        "- Determining the number of epochs, probably on defualt many epochs can be set, but with early stopping to prevent the overfitting in some cases\n",
        "- trying different channel number for the unet architecture: filter_channel argument in the unet model creation function. In the original implementation it is 64, but probably lesser power of 2 can be tried for more efficent, less memory expeensive approach\n",
        "#### Later on\n",
        "- when achieveed some decent score, we may try to extract ground truths and predictions for visulization, for example 10 with the smalles loss for the non crack class and for the crack class, and 10 worse predictions , one with biggest loss, for both crack and non crack\n",
        "\n",
        "\n",
        "- Jedrzej: I will try to run with different parameters and see what the outcomes are , but i think we can do it both, and we can check if it yields some decent result. If not we can think of changing the looose function, or even architecture."
      ],
      "metadata": {
        "id": "S5rCPGOvgCtj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qslFYWa12oJ6"
      },
      "source": [
        "#### Loss functions for the semantic segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KvDjat7Q2sS3"
      },
      "outputs": [],
      "source": [
        "def dice_loss(smooth=1):\n",
        "    def dice_loss_fixed(y_true, y_pred):\n",
        "        # Ensure tensors are in the same shape\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "        # Flatten the tensors\n",
        "        y_true_f = tf.reshape(y_true, [-1])  # Flatten to 1D\n",
        "        y_pred_f = tf.reshape(y_pred, [-1])  # Flatten to 1D\n",
        "\n",
        "        # Compute the intersection\n",
        "        intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "\n",
        "        # Compute Dice coefficient\n",
        "        dice_coeff = (2. * intersection + smooth) / (\n",
        "            tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth\n",
        "        )\n",
        "\n",
        "        # Return Dice loss (1 - Dice coefficient)\n",
        "        return 1 - dice_coeff\n",
        "    return dice_loss_fixed\n",
        "\n",
        "def focal_loss(gamma=2., alpha=0.95):\n",
        "  # alpha = class balancing parameter,\n",
        "  #gamma - penalizing more the bigger mistakes\n",
        "  # adressing the class imbalance , which is defnitely a case in the crack detection, there are much less crack pixels than non crack pixels.\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        pt_1 = tf.where(K.equal(y_true, 1), y_pred, K.ones_like(y_pred))\n",
        "        pt_0 = tf.where(K.equal(y_true, 0), 1 - y_pred, K.ones_like(y_pred))\n",
        "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - \\\n",
        "               K.sum((1 - alpha) * K.pow(1. - pt_0, gamma) * K.log(pt_0))\n",
        "    return focal_loss_fixed\n",
        "def combined_dice_focal_loss(y_true, y_pred):\n",
        "    dice = dice_loss(y_true, y_pred)\n",
        "    focal = focal_loss()(y_true, y_pred)\n",
        "    return 0.5 * dice + 0.5 * focal\n",
        "\n",
        "'''usefull metrics defined to determine the semantic segmentation performance of network '''\n",
        "def crack_precision(y_true, y_pred):\n",
        "    # Apply a threshold to y_pred (sigmoid output) to convert probabilities to binary (0 or 1)\n",
        "    y_pred_bin = K.cast(K.greater(y_pred, 0.5), K.floatx())  # Threshold at 0.5\n",
        "\n",
        "    # Calculate True Positives and False Positives\n",
        "    TP = K.sum(y_true * y_pred_bin)\n",
        "    FP = K.sum((1 - y_true) * y_pred_bin)\n",
        "\n",
        "    # Avoid division by zero (e.g., when no positive class is predicted)\n",
        "    precision = TP / (TP + FP + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def crack_recall(y_true, y_pred):\n",
        "    # Apply a threshold to y_pred (sigmoid output) to convert probabilities to binary (0 or 1)\n",
        "    y_pred_bin = K.cast(K.greater(y_pred, 0.5), K.floatx())  # Threshold at 0.5\n",
        "\n",
        "    # Calculate True Positives and False Negatives\n",
        "    TP = K.sum(y_true * y_pred_bin)\n",
        "    FN = K.sum(y_true * (1 - y_pred_bin))\n",
        "\n",
        "    # Avoid division by zero (e.g., when no positive class exists in the true labels)\n",
        "    recall = TP / (TP + FN + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def non_crack_recall(y_true, y_pred):\n",
        "    # Apply a threshold to y_pred (sigmoid output) to convert probabilities to binary (0 or 1)\n",
        "    y_pred_bin = K.cast(K.greater(y_pred, 0.5), K.floatx())  # Threshold at 0.5\n",
        "\n",
        "    # Calculate True Negatives (TN) and False Positives (FP) for class 0\n",
        "    TN = K.sum((1 - y_true) * (1 - y_pred_bin))  # True Negatives\n",
        "    FP = K.sum((1-y_true) * y_pred_bin)        # False Positives\n",
        "\n",
        "    # Avoid division by zero (e.g., when no non-crack class exists in the true labels)\n",
        "    recall = TN / (TN + FP + K.epsilon())  # Recall formula for class 0\n",
        "    return recall\n",
        "\n",
        "def non_crack_precision(y_true, y_pred):\n",
        "    # Apply a threshold to y_pred (sigmoid output) to convert probabilities to binary (0 or 1)\n",
        "    y_pred_bin = K.cast(K.greater(y_pred, 0.5), K.floatx())  # Threshold at 0.5\n",
        "\n",
        "    # Calculate True Negatives (TN) and False Negatives (FN) for class 0\n",
        "    TN = K.sum((1 - y_true) * (1 - y_pred_bin))  # True Negatives\n",
        "    FN = K.sum(y_true * (1-y_pred_bin))        # False Negatives\n",
        "\n",
        "    # Avoid division by zero (e.g., when no non-crack class exists in the true labels)\n",
        "    precision = TN / (TN + FN + K.epsilon())  # Precision formula for class 0\n",
        "    return precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjFDSuEekcAv"
      },
      "source": [
        "### Testing the unet semantic segmentation\n",
        "\n",
        "firstly we will check the different loss functions on the data, we will start off with the mini batch- of 1 item, since it is quite memory efficent and also since in this case  gradients are derived from every single image, they are noisier. This noise can prevent overfitting to some extent, as it helps the model escape sharp minima in the loss landscape working a bit like stochastic gradient descent.\n",
        "but it can take longer to converge and be very unstable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "E5Tq78Q7eK-P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "b6197c09-8b09-43d9-9702-d42c94433592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "   7679/Unknown \u001b[1m141s\u001b[0m 15ms/step - crack_precision: 0.2140 - crack_recall: 0.6977 - loss: 1449.2589 - non_crack_precision: 0.9907 - non_crack_recall: 0.8897"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m7682/7682\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 17ms/step - crack_precision: 0.2140 - crack_recall: 0.6977 - loss: 1449.1573 - non_crack_precision: 0.9907 - non_crack_recall: 0.8897 - val_crack_precision: 0.2183 - val_crack_recall: 0.6919 - val_loss: 2241.4104 - val_non_crack_precision: 0.9907 - val_non_crack_recall: 0.7166\n",
            "Epoch 2/10\n",
            "\u001b[1m2197/7682\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 15ms/step - crack_precision: 0.2947 - crack_recall: 0.7837 - loss: 1004.4420 - non_crack_precision: 0.9946 - non_crack_recall: 0.9235"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cd28e2ccc956>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrack_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrack_recall\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_crack_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnon_crack_recall\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msegmentation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_early_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "train_ds, val_ds = dataset.get_dataset(split='train', batch_size=1, task='segmentation',stratified=False)\n",
        "\n",
        "segmentation_model = unet_model(input_shape=(448, 448, 3),filter_number=4,segmentation='True')\n",
        "segmentation_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=focal_loss(),\n",
        "    metrics=[crack_precision, crack_recall,non_crack_precision,non_crack_recall]\n",
        ")\n",
        "segmentation_model.fit(train_ds, validation_data=val_ds,callbacks=[epoch_early_stopping], epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds, _ = dataset.get_dataset(split='test', batch_size=1, task='segmentation')\n",
        "loss, crack_precision, crack_recall, non_crack_precision, non_crack_recall = segmentation_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test crack Precision: {crack_precision:.4f}\")\n",
        "print(f\"Test crack Recall: {crack_recall:.4f}\")\n",
        "print(f\"Test non-crack Precision: {non_crack_precision:.4f}\")\n",
        "print(f\"Test non-crack Recall: {non_crack_recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5rvosr48hD8",
        "outputId": "a81c77ec-4442-45d8-9e86-02cd8499781d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1695/1695\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 16ms/step - crack_precision: 0.2903 - crack_recall: 0.5214 - loss: 2136.6626 - non_crack_precision: 0.9779 - non_crack_recall: 0.8548\n",
            "Test Loss: 2098.8083\n",
            "Test crack Precision: 0.2815\n",
            "Test crack Recall: 0.5282\n",
            "Test non-crack Precision: 0.9770\n",
            "Test non-crack Recall: 0.8534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### batch size adjustment"
      ],
      "metadata": {
        "id": "pjGwT41NOpBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "train_ds, val_ds = dataset.get_dataset(split='train', batch_size=8, task='segmentation', stratified=True)\n",
        "\n",
        "segmentation_model = unet_model(input_shape=(448, 448, 3),filter_number=32)\n",
        "segmentation_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=focal_loss(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "segmentation_model.fit(train_ds, validation_data=val_ds,callbacks=[epoch_early_stopping], epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-ffOaKkOara",
        "outputId": "3b9582e9-fe1e-4e73-8ff7-0d9c5a45dd7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    243/Unknown \u001b[1m196s\u001b[0m 521ms/step - accuracy: 0.8579 - loss: 15911.2646"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds, _ = dataset.get_dataset(split='test', batch_size=1, task='segmentation')\n",
        "loss, crack_precision, crack_recall, non_crack_precision, non_crack_recall = segmentation_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "# print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test crack Precision: {crack_precision:.4f}\")\n",
        "print(f\"Test crack Recall: {crack_recall:.4f}\")\n",
        "print(f\"Test non-crack Precision: {non_crack_precision:.4f}\")\n",
        "print(f\"Test non-crack Recall: {non_crack_recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "bjoavdWrOfSQ",
        "outputId": "fcc941d6-ae15-429e-8cad-13ec014b9806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot take the length of shape with unknown rank.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1d6299512eb6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'segmentation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Loss: {loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py\u001b[0m in \u001b[0;36msqueeze_or_expand_to_same_rank\u001b[0;34m(x1, x2, expand_rank_1)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msqueeze_or_expand_to_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_rank_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;34m\"\"\"Squeeze/expand last dim if ranks differ from expected by exactly 1.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mx1_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0mx2_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx1_rank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx2_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot take the length of shape with unknown rank."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other loss functions on the unet model with bigger batch size"
      ],
      "metadata": {
        "id": "8lr_9INsOxYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "train_ds, val_ds = dataset.get_dataset(split='train', batch_size=8, task='segmentation',stratified=True)\n",
        "\n",
        "segmentation_model = unet_model(input_shape=(448, 448, 3),filter_number=32)\n",
        "segmentation_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=dice_loss(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "segmentation_model.fit(train_ds, validation_data=val_ds,callbacks=[epoch_early_stopping], epochs=10)"
      ],
      "metadata": {
        "id": "Fa8MbfCpycWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds, _ = dataset.get_dataset(split='test', batch_size=1, task='segmentation')\n",
        "loss, crack_precision, crack_recall,non_crack_precision,non_crack_recall = segmentation_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"test crack Precision: {crack_precision:.4f}\")\n",
        "print(f\"testc crack Recall: {crack_recall:.4f}\")\n",
        "print(f\"test non-crack Precision: {non_crack_precision:.4f}\")\n",
        "print(f\"testc non-crack Recall: {non_crack_recall:.4f}\")"
      ],
      "metadata": {
        "id": "IIZeUx1m8qRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',       # Monitor validation loss\n",
        "    patience=3,               # Stop training if no improvement for 5 epochs\n",
        "    restore_best_weights=True # Restore the best weights on stopping\n",
        ")\n",
        "\n",
        "\n",
        "train_ds, val_ds = dataset.get_dataset(split='train', batch_size=8, task='segmentation',stratified=True)\n",
        "\n",
        "segmentation_model = unet_model(input_shape=(448, 448, 3), filter_number=32)\n",
        "segmentation_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=combined_dice_focal_loss(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "segmentation_model.fit(train_ds, validation_data=val_ds,callbacks=[epoch_early_stopping], epochs=10)"
      ],
      "metadata": {
        "id": "KULYiBzvyeLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds, _ = dataset.get_dataset(split='test', batch_size=1, task='segmentation')\n",
        "loss, crack_precision, crack_recall,non_crack_precision,non_crack_recall = segmentation_model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"test crack Precision: {crack_precision:.4f}\")\n",
        "print(f\"testc crack Recall: {crack_recall:.4f}\")\n",
        "print(f\"test non-crack Precision: {non_crack_precision:.4f}\")\n",
        "print(f\"testc non-crack Recall: {non_crack_recall:.4f}\")"
      ],
      "metadata": {
        "id": "nnHHbj2o8rdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HmjkS0hctMt"
      },
      "source": [
        "### Unet++ model for semantic segmentation of cracks\n",
        "this is an adjusted  version of the unet architecture which  allows not only for the skip connections between the encoder and decoder  layer on the respective level but also for connections between the decoder and all the encoder below - on deeper level\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = dataset.get_dataset(split='train', batch_size=32, task='segmentation')\n",
        "test_ds = dataset.get_dataset(split='test', batch_size=32, task='segmentation')\n",
        "segmentation_model = unet_plus_plus(input_shape=(448, 448, 3),filter_number=16)\n",
        "segmentation_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='focal_loss',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "segmentation_model.fit(train_ds, validation_data=test_ds, epochs=10)"
      ],
      "metadata": {
        "id": "H0ytheqT7sOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = dataset.get_dataset(split='train', batch_size=32, task='segmentation')\n",
        "test_ds = dataset.get_dataset(split='test', batch_size=32, task='segmentation')\n",
        "segmentation_model = unet_plus_plus(input_shape=(448, 448, 3),filter_number=16)\n",
        "segmentation_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='dice_loss',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "segmentation_model.fit(train_ds, validation_data=test_ds, epochs=10)"
      ],
      "metadata": {
        "id": "ZQDUsH9q7sHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = dataset.get_dataset(split='train', batch_size=32, task='segmentation')\n",
        "test_ds = dataset.get_dataset(split='test', batch_size=32, task='segmentation')\n",
        "segmentation_model = unet_plus_plus(input_shape=(448, 448, 3),filter_number=16)\n",
        "segmentation_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='combined_dice_focal_loss',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "segmentation_model.fit(train_ds, validation_data=test_ds, epochs=10)"
      ],
      "metadata": {
        "id": "iq6QzPM77r69"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}